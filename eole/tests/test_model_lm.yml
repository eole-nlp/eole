src_vocab: /work/eole/tests/data/vocab-train.src
tgt_vocab: /work/eole/tests/data/vocab-train.tgt
model:
  architecture: transformer_lm
  embeddings:
    position_encoding: true
    word_vec_size: 64
    tgt_word_vec_size: 64
    src_word_vec_size: 64
  decoder:
    layers: 2
    heads: 2
    add_ffnbias: true
    add_qkvbias: true
    transformer_ff: 256
    hidden_size: 64
data:
  corpus_1:
    weight: 1
    transforms: []
    path_src: /work/eole/tests/data/src-train.txt
  valid:
    path_src: /work/eole/tests/data/src-val.txt
training:
  batch_size: 256
  train_steps: 10000
  save_checkpoint_steps: 5000
  valid_steps: 10000
  dropout: [0.3]
  dropout_steps: [0]
  learning_rate: 2.0
  adam_beta1: 0.9
  adam_beta2: 0.998
  label_smoothing: 0.1
  save_model: test_model.rebuild
  optim: adam
  decay_method: noam
  warmup_steps: 100
  param_init_method: xavier_uniform
  # distributed
  gpu_ranks: [0]
  world_size: 1
  # dataloading
  bucket_size: 100000
  prefetch_factor: 50000
  bucket_size_init: 20000
  bucket_size_increment: 20000
# vocab
share_vocab: true

