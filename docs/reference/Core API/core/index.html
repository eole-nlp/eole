<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-reference/Core API/core" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.0">
<title data-rh="true">Framework | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://eole-nlp.github.io/eole/docs/reference/Core API/core"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Framework | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress"><meta data-rh="true" name="description" content="Model"><meta data-rh="true" property="og:description" content="Model"><link data-rh="true" rel="icon" href="/eole/img/eole-logo.ico"><link data-rh="true" rel="canonical" href="https://eole-nlp.github.io/eole/docs/reference/Core API/core"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/reference/Core API/core" hreflang="en"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/reference/Core API/core" hreflang="x-default"><link rel="stylesheet" href="/eole/assets/css/styles.0e100862.css">
<script src="/eole/assets/js/runtime~main.57001c96.js" defer="defer"></script>
<script src="/eole/assets/js/main.65cb15d6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/eole/"><div class="navbar__logo"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/eole/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/eole/docs/reference/index">Reference</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/reference/index">Eole Core API</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/eole/docs/reference/Config/">Configuration</a><button aria-label="Expand sidebar category &#x27;Configuration&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/eole/docs/reference/Core API/core">Core API</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/eole/docs/reference/Core API/core">Framework</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Core API/modules">Modules</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Core API/dataloaders">Data Loaders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Core API/inference">Prediction</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/reference/bibliography">Bibliography</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/eole/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Core API</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Framework</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Framework</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="model">Model<a href="#model" class="hash-link" aria-label="Direct link to Model" title="Direct link to Model">‚Äã</a></h2>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="trainer">Trainer<a href="#trainer" class="hash-link" aria-label="Direct link to Trainer" title="Direct link to Trainer">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="class-eoletrainertrainermodel-train_loss-valid_loss-scoring_preparator-valid_scorers-optim-trunc_size0-norm_methodsents-accum_count1-accum_steps0-n_gpu1-gpu_rank1-parallel_modedata_parallel-report_managernone-with_alignfalse-model_savernone-average_decay0-average_every1-earlystoppernone-dropout03-attention_dropout01-dropout_steps0-zero_out_prompt_lossfalse-estim_loss_lambda10-estim_loss_lambda_steps0source"><em>class</em> eole.trainer.Trainer(model, train_loss, valid_loss, scoring_preparator, valid_scorers, optim, trunc_size=0, norm_method=&#x27;sents&#x27;, accum_count=[1], accum_steps=[0], n_gpu=1, gpu_rank=1, parallel_mode=&#x27;data_parallel&#x27;, report_manager=None, with_align=False, model_saver=None, average_decay=0, average_every=1, earlystopper=None, dropout=[0.3], attention_dropout=[0.1], dropout_steps=[0], zero_out_prompt_loss=False, estim_loss_lambda=[1.0], estim_loss_lambda_steps=[0])<a href="https://github.com/eole-nlp/eole/blob/master/eole/trainer.py#L114-L615" target="_blank" rel="noopener noreferrer">[source]</a><a href="#class-eoletrainertrainermodel-train_loss-valid_loss-scoring_preparator-valid_scorers-optim-trunc_size0-norm_methodsents-accum_count1-accum_steps0-n_gpu1-gpu_rank1-parallel_modedata_parallel-report_managernone-with_alignfalse-model_savernone-average_decay0-average_every1-earlystoppernone-dropout03-attention_dropout01-dropout_steps0-zero_out_prompt_lossfalse-estim_loss_lambda10-estim_loss_lambda_steps0source" class="hash-link" aria-label="Direct link to class-eoletrainertrainermodel-train_loss-valid_loss-scoring_preparator-valid_scorers-optim-trunc_size0-norm_methodsents-accum_count1-accum_steps0-n_gpu1-gpu_rank1-parallel_modedata_parallel-report_managernone-with_alignfalse-model_savernone-average_decay0-average_every1-earlystoppernone-dropout03-attention_dropout01-dropout_steps0-zero_out_prompt_lossfalse-estim_loss_lambda10-estim_loss_lambda_steps0source" title="Direct link to class-eoletrainertrainermodel-train_loss-valid_loss-scoring_preparator-valid_scorers-optim-trunc_size0-norm_methodsents-accum_count1-accum_steps0-n_gpu1-gpu_rank1-parallel_modedata_parallel-report_managernone-with_alignfalse-model_savernone-average_decay0-average_every1-earlystoppernone-dropout03-attention_dropout01-dropout_steps0-zero_out_prompt_lossfalse-estim_loss_lambda10-estim_loss_lambda_steps0source">‚Äã</a></h3>
<p>Bases: <code>object</code></p>
<p>Class that controls the training process.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>model</strong> (<code>eole.models.model.BaseModel</code>) ‚Äì model to train</li>
<li><strong>train_loss</strong> (<code>eole.utils.loss.LossComputeBase</code>) ‚Äì training loss computation</li>
<li><strong>valid_loss</strong> (<code>eole.utils.loss.LossComputeBase</code>) ‚Äì training loss computation</li>
<li><strong>scoring_preparator</strong> (<code>eole.predict.utils.ScoringPreparator</code>) ‚Äì preparator for the calculation of metrics via the
_eval_handler method</li>
<li><strong>valid_scorers</strong> (<em>dict</em>) ‚Äì keeps in memory the current values
of the validation metrics</li>
<li><strong>optim</strong> (<a href="#eole.utils.Optimizer"><code>eole.utils.optimizers.Optimizer</code></a>) ‚Äì the optimizer responsible for update</li>
<li><strong>trunc_size</strong> (<em>int</em>) ‚Äì length of truncated back propagation
through time</li>
<li><strong>accum_count</strong> (<em>list</em>) ‚Äì accumulate gradients this many times.</li>
<li><strong>accum_steps</strong> (<em>list</em>) ‚Äì steps for accum gradients changes.</li>
<li><strong>n_gpu</strong> (<em>int</em>) ‚Äì number of gpu.</li>
<li><strong>gpu_rank</strong> (<em>int</em>) ‚Äì ordinal rank of the gpu in the list.</li>
<li><strong>report_manager</strong> (<code>eole.utils.ReportMgrBase</code>) ‚Äì the object that creates reports, or None</li>
<li><strong>with_align</strong> (<em>bool</em>) ‚Äì whether to jointly lear alignment
(Transformer)</li>
<li><strong>model_saver</strong> (<code>eole.models.ModelSaverBase</code>) ‚Äì the saver is
used to save a checkpoint.
Thus nothing will be saved if this parameter is None.</li>
<li><strong>average_decay</strong> (<em>float</em>) ‚Äì cf opt.average_decay</li>
<li><strong>average_every</strong> (<em>int</em>) ‚Äì average model every x steps.</li>
<li><strong>earlystopper</strong> (<code>eole.utils.EarlyStopping</code>) ‚Äì add early
stopping mecanism</li>
<li><strong>dropout</strong> (<em>float</em>) ‚Äì dropout value in RNN or FF layers.</li>
<li><strong>attention_dropout</strong> (<em>float</em>) ‚Äì dropaout in attention layers.</li>
<li><strong>dropout_steps</strong> (<em>list</em>) ‚Äì dropout values scheduling in steps.</li>
<li><strong>zero_out_prompt_loss</strong> (<em>bool</em>) ‚Äì whether to zero-out the prompt loss
(mostly for LLM finetuning).</li>
<li><strong>estim_loss_lambda</strong> (<em>List</em> *[*<em>float</em> <em>]</em>) ‚Äì weight applied to estimator loss</li>
<li><strong>estim_loss_lambda_steps</strong> (<em>List</em> *[*<em>int</em> <em>]</em>) ‚Äì steps to apply to estimator values</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="traintrain_iter-train_steps-save_checkpoint_steps5000-valid_iternone-valid_steps10000source">train(train_iter, train_steps, save_checkpoint_steps=5000, valid_iter=None, valid_steps=10000)<a href="https://github.com/eole-nlp/eole/blob/master/eole/trainer.py#L292-L382" target="_blank" rel="noopener noreferrer">[source]</a><a href="#traintrain_iter-train_steps-save_checkpoint_steps5000-valid_iternone-valid_steps10000source" class="hash-link" aria-label="Direct link to traintrain_iter-train_steps-save_checkpoint_steps5000-valid_iternone-valid_steps10000source" title="Direct link to traintrain_iter-train_steps-save_checkpoint_steps5000-valid_iternone-valid_steps10000source">‚Äã</a></h4>
<p>The main training loop by iterating over <code>train_iter</code> and possibly
running validation on <code>valid_iter</code>.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>train_iter</strong> ‚Äì An iterator that returns the next training batch.</li>
<li><strong>train_steps</strong> ‚Äì Run training for this many iterations.</li>
<li><strong>save_checkpoint_steps</strong> ‚Äì Save a checkpoint every this many
iterations.</li>
<li><strong>valid_iter</strong> ‚Äì A generator that returns the next validation batch.</li>
<li><strong>valid_steps</strong> ‚Äì Run evaluation every this many iterations.</li>
</ul>
</li>
<li><strong>Returns:</strong>
training loss statistics</li>
<li><strong>Return type:</strong>
:obj:<code>nmt.Statistics</code></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validatevalid_iter-moving_averagenonesource">validate(valid_iter, moving_average=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/trainer.py#L384-L480" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validatevalid_iter-moving_averagenonesource" class="hash-link" aria-label="Direct link to validatevalid_iter-moving_averagenonesource" title="Direct link to validatevalid_iter-moving_averagenonesource">‚Äã</a></h4>
<p>Validate model.</p>
<ul>
<li><strong>Parameters:</strong>
<strong>valid_iter</strong> ‚Äì validate data iterator</li>
<li><strong>Returns:</strong>
validation loss statistics</li>
<li><strong>Return type:</strong>
:obj:<code>nmt.Statistics</code></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="class-eoleutilsstatisticsloss0-auxloss0-n_batchs0-n_sents0-n_words0-n_correct0-computed_metricssource"><em>class</em> eole.utils.Statistics(loss=0, auxloss=0, n_batchs=0, n_sents=0, n_words=0, n_correct=0, computed_metrics={})<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L10-L182" target="_blank" rel="noopener noreferrer">[source]</a><a href="#class-eoleutilsstatisticsloss0-auxloss0-n_batchs0-n_sents0-n_words0-n_correct0-computed_metricssource" class="hash-link" aria-label="Direct link to class-eoleutilsstatisticsloss0-auxloss0-n_batchs0-n_sents0-n_words0-n_correct0-computed_metricssource" title="Direct link to class-eoleutilsstatisticsloss0-auxloss0-n_batchs0-n_sents0-n_words0-n_correct0-computed_metricssource">‚Äã</a></h3>
<p>Bases: <code>object</code></p>
<p>Accumulator for loss statistics.
Currently calculates:</p>
<ul>
<li>accuracy</li>
<li>perplexity</li>
<li>elapsed time</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="accuracysource">accuracy()<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L110-L112" target="_blank" rel="noopener noreferrer">[source]</a><a href="#accuracysource" class="hash-link" aria-label="Direct link to accuracysource" title="Direct link to accuracysource">‚Äã</a></h4>
<p>compute accuracy</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="static-all_gather_statsstat-max_size4096source"><em>static</em> all_gather_stats(stat, max_size=4096)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L40-L54" target="_blank" rel="noopener noreferrer">[source]</a><a href="#static-all_gather_statsstat-max_size4096source" class="hash-link" aria-label="Direct link to static-all_gather_statsstat-max_size4096source" title="Direct link to static-all_gather_statsstat-max_size4096source">‚Äã</a></h4>
<p>Gather a Statistics object accross multiple process/nodes</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>stat</strong>**(** ‚Äì obj:Statistics): the statistics object to gather
accross all processes/nodes</li>
<li><strong>max_size</strong> (<em>int</em>) ‚Äì max buffer size to use</li>
</ul>
</li>
<li><strong>Returns:</strong>
Statistics, the update stats object</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="static-all_gather_stats_liststat_list-max_size4096source"><em>static</em> all_gather_stats_list(stat_list, max_size=4096)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L56-L82" target="_blank" rel="noopener noreferrer">[source]</a><a href="#static-all_gather_stats_liststat_list-max_size4096source" class="hash-link" aria-label="Direct link to static-all_gather_stats_liststat_list-max_size4096source" title="Direct link to static-all_gather_stats_liststat_list-max_size4096source">‚Äã</a></h4>
<p>Gather a Statistics list accross all processes/nodes</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>stat_list</strong> (list([Statistics])) ‚Äì list of statistics objects to
gather accross all processes/nodes</li>
<li><strong>max_size</strong> (<em>int</em>) ‚Äì max buffer size to use</li>
</ul>
</li>
<li><strong>Returns:</strong>
list of updated stats</li>
<li><strong>Return type:</strong>
our_stats(list([Statistics]))</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="computed_metricmetricsource">computed_metric(metric)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L105-L108" target="_blank" rel="noopener noreferrer">[source]</a><a href="#computed_metricmetricsource" class="hash-link" aria-label="Direct link to computed_metricmetricsource" title="Direct link to computed_metricmetricsource">‚Äã</a></h4>
<p>check if metric(TER/BLEU) is computed and return it</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="elapsed_timesource">elapsed_time()<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L125-L127" target="_blank" rel="noopener noreferrer">[source]</a><a href="#elapsed_timesource" class="hash-link" aria-label="Direct link to elapsed_timesource" title="Direct link to elapsed_timesource">‚Äã</a></h4>
<p>compute elapsed time</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="log_tensorboardprefix-writer-learning_rate-patience-stepsource">log_tensorboard(prefix, writer, learning_rate, patience, step)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L171-L182" target="_blank" rel="noopener noreferrer">[source]</a><a href="#log_tensorboardprefix-writer-learning_rate-patience-stepsource" class="hash-link" aria-label="Direct link to log_tensorboardprefix-writer-learning_rate-patience-stepsource" title="Direct link to log_tensorboardprefix-writer-learning_rate-patience-stepsource">‚Äã</a></h4>
<p>display statistics to tensorboard</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="outputstep-num_steps-learning_rate-startsource">output(step, num_steps, learning_rate, start)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L129-L169" target="_blank" rel="noopener noreferrer">[source]</a><a href="#outputstep-num_steps-learning_rate-startsource" class="hash-link" aria-label="Direct link to outputstep-num_steps-learning_rate-startsource" title="Direct link to outputstep-num_steps-learning_rate-startsource">‚Äã</a></h4>
<p>Write out statistics to stdout.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>step</strong> (<em>int</em>) ‚Äì current step</li>
<li><strong>n_batch</strong> (<em>int</em>) ‚Äì total batches</li>
<li><strong>start</strong> (<em>int</em>) ‚Äì start time of step.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="pplsource">ppl()<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L121-L123" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pplsource" class="hash-link" aria-label="Direct link to pplsource" title="Direct link to pplsource">‚Äã</a></h4>
<p>compute perplexity</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="updatestat-update_n_src_wordsfalsesource">update(stat, update_n_src_words=False)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L84-L103" target="_blank" rel="noopener noreferrer">[source]</a><a href="#updatestat-update_n_src_wordsfalsesource" class="hash-link" aria-label="Direct link to updatestat-update_n_src_wordsfalsesource" title="Direct link to updatestat-update_n_src_wordsfalsesource">‚Äã</a></h4>
<p>Update statistics by suming values with another Statistics object</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>stat</strong> ‚Äì another statistic object</li>
<li><strong>update_n_src_words</strong> (<em>bool</em>) ‚Äì whether to update (sum) n_src_words
or not</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="xentsource">xent()<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/statistics.py#L114-L116" target="_blank" rel="noopener noreferrer">[source]</a><a href="#xentsource" class="hash-link" aria-label="Direct link to xentsource" title="Direct link to xentsource">‚Äã</a></h4>
<p>compute cross entropy</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="loss">Loss<a href="#loss" class="hash-link" aria-label="Direct link to Loss" title="Direct link to Loss">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="class-eoleutilslosslosscomputecriterion-generator-lambda_coverage00-lambda_align00-tgt_shift_index1-vocabsnone-lm_generatornone-lm_prior_lambdanone-lm_prior_taunone-lm_prior_modelnonesource"><em>class</em> eole.utils.loss.LossCompute(criterion, generator, lambda_coverage=0.0, lambda_align=0.0, tgt_shift_index=1, vocabs=None, lm_generator=None, lm_prior_lambda=None, lm_prior_tau=None, lm_prior_model=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/loss.py#L21-L386" target="_blank" rel="noopener noreferrer">[source]</a><a href="#class-eoleutilslosslosscomputecriterion-generator-lambda_coverage00-lambda_align00-tgt_shift_index1-vocabsnone-lm_generatornone-lm_prior_lambdanone-lm_prior_taunone-lm_prior_modelnonesource" class="hash-link" aria-label="Direct link to class-eoleutilslosslosscomputecriterion-generator-lambda_coverage00-lambda_align00-tgt_shift_index1-vocabsnone-lm_generatornone-lm_prior_lambdanone-lm_prior_taunone-lm_prior_modelnonesource" title="Direct link to class-eoleutilslosslosscomputecriterion-generator-lambda_coverage00-lambda_align00-tgt_shift_index1-vocabsnone-lm_generatornone-lm_prior_lambdanone-lm_prior_taunone-lm_prior_modelnonesource">‚Äã</a></h3>
<p>Bases: <code>Module</code></p>
<p>Class for managing efficient loss computation. Handles
accumulating multiple loss computations.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>criterion</strong> (<code>nn. loss function</code>) ‚Äì NLLoss or customed loss</li>
<li><strong>generator</strong> (<code>nn.Module</code>)</li>
<li><strong>lambda_coverage</strong> ‚Äì Hyper-param to apply coverage attention if any</li>
<li><strong>lambda_align</strong> ‚Äì Hyper-param for alignment loss</li>
<li><strong>tgt_shift_index</strong> (<em>int</em>) ‚Äì 1 for NMT, 0 for LM</li>
<li><strong>vocabs</strong> ‚Äì full vocabs with specials
module that maps the output of the decoder to a
distribution over the target vocabulary.</li>
<li><strong>lm_generator</strong> (<code>ctranslate2.Generator</code>) ‚Äì LM Generator</li>
<li><strong>lm_prior_lambda</strong> (<em>float</em>) ‚Äì weight of LM model in loss</li>
<li><strong>lm_prior_tau</strong> (<em>float</em>) ‚Äì scaler for LM loss</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="forwardbatch-output-attns-trunc_start0-trunc_sizenone-estimnonesource">forward(batch, output, attns, trunc_start=0, trunc_size=None, estim=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/loss.py#L273-L357" target="_blank" rel="noopener noreferrer">[source]</a><a href="#forwardbatch-output-attns-trunc_start0-trunc_sizenone-estimnonesource" class="hash-link" aria-label="Direct link to forwardbatch-output-attns-trunc_start0-trunc_sizenone-estimnonesource" title="Direct link to forwardbatch-output-attns-trunc_start0-trunc_sizenone-estimnonesource">‚Äã</a></h4>
<p>Compute the forward loss, supports truncated BPTT for long
sequences by taking a range in the decoder output sequence to
back propagate in.
Range is from (trunc_start, trunc_start + trunc_size).
Truncation is an approximate efficiency trick to relieve the
memory required in the RNN buffers.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>batch</strong> (<em>batch</em>) ‚Äì batch of labeled examples</li>
<li><strong>output</strong> (<code>FloatTensor</code>) ‚Äì output of decoder model <code>(batch, tgt_len, hidden)</code></li>
<li><strong>attns</strong> (<em>dict</em>) ‚Äì dictionary of attention weights
<code>(batch, tgt_len, src_len)</code></li>
<li><strong>trunc_start</strong> (<em>int</em>) ‚Äì starting position of truncation window</li>
<li><strong>trunc_size</strong> (<em>int</em>) ‚Äì length of truncation window</li>
</ul>
</li>
<li><strong>Returns:</strong>
A tuple with the loss and a <a href="#eole.utils.Statistics"><code>eole.utils.Statistics</code></a> instance.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="classmethod-from_configconfig-model-vocabs-traintruesource"><em>classmethod</em> from_config(config, model, vocabs, train=True)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/loss.py#L70-L155" target="_blank" rel="noopener noreferrer">[source]</a><a href="#classmethod-from_configconfig-model-vocabs-traintruesource" class="hash-link" aria-label="Direct link to classmethod-from_configconfig-model-vocabs-traintruesource" title="Direct link to classmethod-from_configconfig-model-vocabs-traintruesource">‚Äã</a></h4>
<p>Returns a subclass which wraps around an nn.Module subclass
(such as nn.NLLLoss) which defines the loss criterion. The LossCompute
object passes relevant data to a Statistics object which handles
training/validation logging.
The Criterion and LossCompute options are triggered by opt settings.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ignore_promptbatchsource">ignore_prompt(batch)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/loss.py#L251-L271" target="_blank" rel="noopener noreferrer">[source]</a><a href="#ignore_promptbatchsource" class="hash-link" aria-label="Direct link to ignore_promptbatchsource" title="Direct link to ignore_promptbatchsource">‚Äã</a></h4>
<p>Mask the prompt in the target side of the batch examples in order
: to set the loss of the prompt to zero.</p>
<p>For finetuning on specific tasks.
The end of the prompt must be indicated by the DefaultTokens.MASK_BEFORE</p>
<blockquote>
<p>placeholder.</p>
</blockquote>
<p>The masks are supposed to be properly handled by the loss criterion
: (e.g. nn.CrossEntropyLoss ).</p>
<ul>
<li><strong>Parameters:</strong>
<strong>batch</strong> ‚Äì The current batch.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="optimizer">Optimizer<a href="#optimizer" class="hash-link" aria-label="Direct link to Optimizer" title="Direct link to Optimizer">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="class-eoleutilsoptimizeroptimizer-learning_rate-learning_rate_decay_fnnone-max_grad_normnonesource"><em>class</em> eole.utils.Optimizer(optimizer, learning_rate, learning_rate_decay_fn=None, max_grad_norm=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L305-L493" target="_blank" rel="noopener noreferrer">[source]</a><a href="#class-eoleutilsoptimizeroptimizer-learning_rate-learning_rate_decay_fnnone-max_grad_normnonesource" class="hash-link" aria-label="Direct link to class-eoleutilsoptimizeroptimizer-learning_rate-learning_rate_decay_fnnone-max_grad_normnonesource" title="Direct link to class-eoleutilsoptimizeroptimizer-learning_rate-learning_rate_decay_fnnone-max_grad_normnonesource">‚Äã</a></h3>
<p>Bases: <code>object</code></p>
<p>Controller class for optimization. Mostly a thin
wrapper for optim, but also useful for implementing
rate scheduling beyond what is currently available.
Also implements necessary methods for training RNNs such
as grad manipulations.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>optimizer</strong> ‚Äì A <code>torch.optim.Optimizer</code> instance.</li>
<li><strong>learning_rate</strong> ‚Äì The initial learning rate.</li>
<li><strong>learning_rate_decay_fn</strong> ‚Äì An optional callable taking the current step
as argument and return a learning rate scaling factor.</li>
<li><strong>max_grad_norm</strong> ‚Äì Clip gradients to this global norm.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="property-ampsource"><em>property</em> amp<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L408-L411" target="_blank" rel="noopener noreferrer">[source]</a><a href="#property-ampsource" class="hash-link" aria-label="Direct link to property-ampsource" title="Direct link to property-ampsource">‚Äã</a></h4>
<p>True if use torch amp mix precision training.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="backwardlosssource">backward(loss)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L444-L458" target="_blank" rel="noopener noreferrer">[source]</a><a href="#backwardlosssource" class="hash-link" aria-label="Direct link to backwardlosssource" title="Direct link to backwardlosssource">‚Äã</a></h4>
<p>Wrapper for backward pass. Some optimizer requires ownership of the
backward pass.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="classmethod-from_configmodel-config-checkpointnonesource"><em>classmethod</em> from_config(model, config, checkpoint=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L333-L401" target="_blank" rel="noopener noreferrer">[source]</a><a href="#classmethod-from_configmodel-config-checkpointnonesource" class="hash-link" aria-label="Direct link to classmethod-from_configmodel-config-checkpointnonesource" title="Direct link to classmethod-from_configmodel-config-checkpointnonesource">‚Äã</a></h4>
<p>Builds the optimizer from options.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>cls</strong> ‚Äì The <code>Optimizer</code> class to instantiate.</li>
<li><strong>model</strong> ‚Äì The model to optimize.</li>
<li><strong>opt</strong> ‚Äì The dict of user options.</li>
<li><strong>checkpoint</strong> ‚Äì An optional checkpoint to load states from.</li>
</ul>
</li>
<li><strong>Returns:</strong>
An <code>Optimizer</code> instance.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="learning_ratestepnonesource">learning_rate(step=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L413-L420" target="_blank" rel="noopener noreferrer">[source]</a><a href="#learning_ratestepnonesource" class="hash-link" aria-label="Direct link to learning_ratestepnonesource" title="Direct link to learning_ratestepnonesource">‚Äã</a></h4>
<p>Returns the current learning rate.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="stepsource">step()<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L460-L493" target="_blank" rel="noopener noreferrer">[source]</a><a href="#stepsource" class="hash-link" aria-label="Direct link to stepsource" title="Direct link to stepsource">‚Äã</a></h4>
<p>Update the model parameters based on current gradients.</p>
<p>Optionally, will employ gradient modification or update learning
rate.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="property-training_stepsource"><em>property</em> training_step<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L403-L406" target="_blank" rel="noopener noreferrer">[source]</a><a href="#property-training_stepsource" class="hash-link" aria-label="Direct link to property-training_stepsource" title="Direct link to property-training_stepsource">‚Äã</a></h4>
<p>The current training step.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="zero_gradset_to_nonetruesource">zero_grad(set_to_none=True)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L437-L442" target="_blank" rel="noopener noreferrer">[source]</a><a href="#zero_gradset_to_nonetruesource" class="hash-link" aria-label="Direct link to zero_gradset_to_nonetruesource" title="Direct link to zero_gradset_to_nonetruesource">‚Äã</a></h4>
<p>Zero the gradients of optimized parameters.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="class-eoleutilsadafactorparams-lrnone-beta109-beta20999-eps11e-30-eps20001-cliping_threshold1-non_constant_decaytrue-enable_factorizationtrue-ams_gradtrue-weight_decay0source"><em>class</em> eole.utils.AdaFactor(params, lr=None, beta1=0.9, beta2=0.999, eps1=1e-30, eps2=0.001, cliping_threshold=1, non_constant_decay=True, enable_factorization=True, ams_grad=True, weight_decay=0)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L500-L705" target="_blank" rel="noopener noreferrer">[source]</a><a href="#class-eoleutilsadafactorparams-lrnone-beta109-beta20999-eps11e-30-eps20001-cliping_threshold1-non_constant_decaytrue-enable_factorizationtrue-ams_gradtrue-weight_decay0source" class="hash-link" aria-label="Direct link to class-eoleutilsadafactorparams-lrnone-beta109-beta20999-eps11e-30-eps20001-cliping_threshold1-non_constant_decaytrue-enable_factorizationtrue-ams_gradtrue-weight_decay0source" title="Direct link to class-eoleutilsadafactorparams-lrnone-beta109-beta20999-eps11e-30-eps20001-cliping_threshold1-non_constant_decaytrue-enable_factorizationtrue-ams_gradtrue-weight_decay0source">‚Äã</a></h3>
<p>Bases: <code>Optimizer</code></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="stepclosurenonesource">step(closure=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L568-L705" target="_blank" rel="noopener noreferrer">[source]</a><a href="#stepclosurenonesource" class="hash-link" aria-label="Direct link to stepclosurenonesource" title="Direct link to stepclosurenonesource">‚Äã</a></h4>
<p>Perform a single optimization step to update parameter.</p>
<ul>
<li><strong>Parameters:</strong>
<strong>closure</strong> (<em>Callable</em>) ‚Äì A closure that reevaluates the model and
returns the loss. Optional for most optimizers.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="note">NOTE<a href="#note" class="hash-link" aria-label="Direct link to NOTE" title="Direct link to NOTE">‚Äã</a></h4>
<p>Unless otherwise specified, this function should not modify the
<code>.grad</code> field of the parameters.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="class-eoleutilsfusedadamparams-lr0001-bias_correctiontrue-betas09-0999-eps1e-08-eps_inside_sqrtfalse-weight_decay00-max_grad_norm00-amsgradfalsesource"><em>class</em> eole.utils.FusedAdam(params, lr=0.001, bias_correction=True, betas=(0.9, 0.999), eps=1e-08, eps_inside_sqrt=False, weight_decay=0.0, max_grad_norm=0.0, amsgrad=False)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L708-L876" target="_blank" rel="noopener noreferrer">[source]</a><a href="#class-eoleutilsfusedadamparams-lr0001-bias_correctiontrue-betas09-0999-eps1e-08-eps_inside_sqrtfalse-weight_decay00-max_grad_norm00-amsgradfalsesource" class="hash-link" aria-label="Direct link to class-eoleutilsfusedadamparams-lr0001-bias_correctiontrue-betas09-0999-eps1e-08-eps_inside_sqrtfalse-weight_decay00-max_grad_norm00-amsgradfalsesource" title="Direct link to class-eoleutilsfusedadamparams-lr0001-bias_correctiontrue-betas09-0999-eps1e-08-eps_inside_sqrtfalse-weight_decay00-max_grad_norm00-amsgradfalsesource">‚Äã</a></h3>
<p>Bases: <code>Optimizer</code></p>
<p>Implements Adam algorithm. Currently GPU-only.
: Requires Apex to be installed via
<code>python setup.py install --cuda_ext --cpp_ext</code>.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>params</strong> (<em>iterable</em>) ‚Äì iterable of parameters to optimize or dicts defining
parameter groups.</li>
<li><strong>lr</strong> (<em>float</em> <em>,</em> <em>optional</em>) ‚Äì learning rate. (default: 1e-3)</li>
<li><strong>betas</strong> (<em>Tuple</em> *[*<em>float</em> <em>,</em> <em>float</em> <em>]</em> <em>,</em> <em>optional</em>) ‚Äì coefficients used for computing
running averages of gradient and its square.
(default: (0.9, 0.999))</li>
<li><strong>eps</strong> (<em>float</em> <em>,</em> <em>optional</em>) ‚Äì term added to the denominator to improve
numerical stability. (default: 1e-8)</li>
<li><strong>weight_decay</strong> (<em>float</em> <em>,</em> <em>optional</em>) ‚Äì weight decay (L2 penalty) (default: 0)</li>
<li><strong>amsgrad</strong> (<em>boolean</em> <em>,</em> <em>optional</em>) ‚Äì whether to use the AMSGrad variant of this
algorithm from the paper ‚ÄòOn the Convergence of Adam and Beyond‚Äô
(default: False) NOT SUPPORTED in FusedAdam!</li>
<li><strong>eps_inside_sqrt</strong> (<em>boolean</em> <em>,</em> <em>optional</em>) ‚Äì in the ‚Äòupdate parameters‚Äô step,
adds eps to the bias-corrected second moment estimate before
evaluating square root instead of adding it to the square root of
second moment estimate as in the original paper. (default: False)</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="stepclosurenone-gradsnone-output_paramsnone-scale10-grad_normsnonesource">step(closure=None, grads=None, output_params=None, scale=1.0, grad_norms=None)<a href="https://github.com/eole-nlp/eole/blob/master/eole/utils/optimizers.py#L761-L876" target="_blank" rel="noopener noreferrer">[source]</a><a href="#stepclosurenone-gradsnone-output_paramsnone-scale10-grad_normsnonesource" class="hash-link" aria-label="Direct link to stepclosurenone-gradsnone-output_paramsnone-scale10-grad_normsnonesource" title="Direct link to stepclosurenone-gradsnone-output_paramsnone-scale10-grad_normsnonesource">‚Äã</a></h4>
<p>Performs a single optimization step.</p>
<ul>
<li><strong>Parameters:</strong>
<ul>
<li><strong>closure</strong> (<em>callable</em> <em>,</em> <em>optional</em>) ‚Äì A closure that reevaluates the model
and returns the loss.</li>
<li><strong>grads</strong> (<em>list</em> <em>of</em> <em>tensors</em> <em>,</em> <em>optional</em>) ‚Äì weight gradient to use for the
optimizer update. If gradients have type torch.half, parameters
are expected to be in type torch.float. (default: None)</li>
<li><strong>params</strong> (<em>output</em>) ‚Äì A reduced precision copy
of the updated weights written out in addition to the regular
updated weights. Have to be of same type as gradients.
(default: None)</li>
<li><strong>scale</strong> (<em>float</em> <em>,</em> <em>optional</em>) ‚Äì factor to divide gradient tensor values
by before applying to weights. (default: 1)</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/eole-nlp/eole/tree/main/docs/docs/reference/Core API/0_core.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/eole/docs/reference/Config/transforms"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Transforms</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/eole/docs/reference/Core API/modules"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Modules</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#model" class="table-of-contents__link toc-highlight">Model</a></li><li><a href="#trainer" class="table-of-contents__link toc-highlight">Trainer</a><ul><li><a href="#class-eoletrainertrainermodel-train_loss-valid_loss-scoring_preparator-valid_scorers-optim-trunc_size0-norm_methodsents-accum_count1-accum_steps0-n_gpu1-gpu_rank1-parallel_modedata_parallel-report_managernone-with_alignfalse-model_savernone-average_decay0-average_every1-earlystoppernone-dropout03-attention_dropout01-dropout_steps0-zero_out_prompt_lossfalse-estim_loss_lambda10-estim_loss_lambda_steps0source" class="table-of-contents__link toc-highlight"><em>class</em> eole.trainer.Trainer(model, train_loss, valid_loss, scoring_preparator, valid_scorers, optim, trunc_size=0, norm_method=&#39;sents&#39;, accum_count=[1], accum_steps=[0], n_gpu=1, gpu_rank=1, parallel_mode=&#39;data_parallel&#39;, report_manager=None, with_align=False, model_saver=None, average_decay=0, average_every=1, earlystopper=None, dropout=[0.3], attention_dropout=[0.1], dropout_steps=[0], zero_out_prompt_loss=False, estim_loss_lambda=[1.0], estim_loss_lambda_steps=[0])[source]</a></li><li><a href="#class-eoleutilsstatisticsloss0-auxloss0-n_batchs0-n_sents0-n_words0-n_correct0-computed_metricssource" class="table-of-contents__link toc-highlight"><em>class</em> eole.utils.Statistics(loss=0, auxloss=0, n_batchs=0, n_sents=0, n_words=0, n_correct=0, computed_metrics={})[source]</a></li></ul></li><li><a href="#loss" class="table-of-contents__link toc-highlight">Loss</a><ul><li><a href="#class-eoleutilslosslosscomputecriterion-generator-lambda_coverage00-lambda_align00-tgt_shift_index1-vocabsnone-lm_generatornone-lm_prior_lambdanone-lm_prior_taunone-lm_prior_modelnonesource" class="table-of-contents__link toc-highlight"><em>class</em> eole.utils.loss.LossCompute(criterion, generator, lambda_coverage=0.0, lambda_align=0.0, tgt_shift_index=1, vocabs=None, lm_generator=None, lm_prior_lambda=None, lm_prior_tau=None, lm_prior_model=None)[source]</a></li></ul></li><li><a href="#optimizer" class="table-of-contents__link toc-highlight">Optimizer</a><ul><li><a href="#class-eoleutilsoptimizeroptimizer-learning_rate-learning_rate_decay_fnnone-max_grad_normnonesource" class="table-of-contents__link toc-highlight"><em>class</em> eole.utils.Optimizer(optimizer, learning_rate, learning_rate_decay_fn=None, max_grad_norm=None)[source]</a></li><li><a href="#class-eoleutilsadafactorparams-lrnone-beta109-beta20999-eps11e-30-eps20001-cliping_threshold1-non_constant_decaytrue-enable_factorizationtrue-ams_gradtrue-weight_decay0source" class="table-of-contents__link toc-highlight"><em>class</em> eole.utils.AdaFactor(params, lr=None, beta1=0.9, beta2=0.999, eps1=1e-30, eps2=0.001, cliping_threshold=1, non_constant_decay=True, enable_factorization=True, ams_grad=True, weight_decay=0)[source]</a></li><li><a href="#class-eoleutilsfusedadamparams-lr0001-bias_correctiontrue-betas09-0999-eps1e-08-eps_inside_sqrtfalse-weight_decay00-max_grad_norm00-amsgradfalsesource" class="table-of-contents__link toc-highlight"><em>class</em> eole.utils.FusedAdam(params, lr=0.001, bias_correction=True, betas=(0.9, 0.999), eps=1e-08, eps_inside_sqrt=False, weight_decay=0.0, max_grad_norm=0.0, amsgrad=False)[source]</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/eole/docs/">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="footer__link-item">Source<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">EOLE is an open-source toolkit and is licensed under the MIT license.</div></div></div></footer></div>
</body>
</html>