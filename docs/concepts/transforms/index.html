<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-concepts/transforms" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.0">
<title data-rh="true">Data Transforms | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://eole-nlp.github.io/eole/docs/concepts/transforms"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Data Transforms | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress"><meta data-rh="true" name="description" content="Recap of available on-the-fly data transforms."><meta data-rh="true" property="og:description" content="Recap of available on-the-fly data transforms."><link data-rh="true" rel="icon" href="/eole/img/eole-logo.ico"><link data-rh="true" rel="canonical" href="https://eole-nlp.github.io/eole/docs/concepts/transforms"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/concepts/transforms" hreflang="en"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/concepts/transforms" hreflang="x-default"><link rel="stylesheet" href="/eole/assets/css/styles.0e100862.css">
<script src="/eole/assets/js/runtime~main.4f1c800a.js" defer="defer"></script>
<script src="/eole/assets/js/main.7d23c672.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/eole/"><div class="navbar__logo"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/eole/docs/">Docs</a><a class="navbar__item navbar__link" href="/eole/docs/reference/index">Reference</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/">EOLE</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/quickstart">Quickstart</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/eole/docs/category/key-concepts">Key Concepts</a><button aria-label="Collapse sidebar category &#x27;Key Concepts&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/concepts/config">Configuration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/concepts/command_line">Command Line</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/concepts/weighting">Dataset Weighting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/eole/docs/concepts/transforms">Data Transforms</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/eole/docs/category/frequently-asked-questions">Frequently Asked Questions</a><button aria-label="Expand sidebar category &#x27;Frequently Asked Questions&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/eole/docs/category/recipes">Recipes</a><button aria-label="Expand sidebar category &#x27;Recipes&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/contributing">Contributors</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/eole/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/eole/docs/category/key-concepts"><span itemprop="name">Key Concepts</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Data Transforms</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Data Transforms</h1>
<p>It&#x27;s your lucky day! We already embedded several transforms that can be used easily.</p>
<p>Note: all the details about every flag and options for each transform can be found in the <a href="/eole/docs/reference/Config/transforms">Transforms Config</a> section.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transform-types">Transform Types<a href="#transform-types" class="hash-link" aria-label="Direct link to Transform Types" title="Direct link to Transform Types">‚Äã</a></h3>
<p>The concept of <code>TransformType</code> was introduced to facilitate transparent configuration management. The underlying issue at stake is that all transforms are not meant to be used in the same concept. For instance, the <code>filtertoolong</code> transform is meant as a &quot;safeguard&quot; to limit the size of training batches. Enabling this transform when predicting can introduce some unwanted behaviours and poor results.
For now, the possible transform types are:</p>
<ul>
<li><code>Default</code> // <code>&quot;any&quot;</code>: usable in any context (default unless specified otherwise in the transform class definition);</li>
<li><code>Train</code> // <code>&quot;train&quot;</code>: usable only in training context;</li>
<li><code>Predict</code> // <code>&quot;predict&quot;</code>: usable only in prediction context.</li>
</ul>
<p>This concept might be extended later for various needs, such as different data types, etc.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="general-purpose">General purpose<a href="#general-purpose" class="hash-link" aria-label="Direct link to General purpose" title="Direct link to General purpose">‚Äã</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="filter-examples-by-length">Filter examples by length<a href="#filter-examples-by-length" class="hash-link" aria-label="Direct link to Filter examples by length" title="Direct link to Filter examples by length">‚Äã</a></h4>
<p>Transform name: <code>filtertoolong</code></p>
<p>Class: <code>eole.transforms.misc.FilterTooLongTransform</code></p>
<p>The following options can be added to the configuration :</p>
<ul>
<li><code>src_seq_length</code>: maximum source sequence length;</li>
<li><code>tgt_seq_length</code>: maximum target sequence length.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="add-custom-prefix-to-examples">Add custom prefix to examples<a href="#add-custom-prefix-to-examples" class="hash-link" aria-label="Direct link to Add custom prefix to examples" title="Direct link to Add custom prefix to examples">‚Äã</a></h4>
<p>Transform name: <code>prefix</code></p>
<p>Class: <code>eole.transforms.misc.PrefixTransform</code></p>
<p>For each dataset that the <code>prefix</code> transform is applied to, you can set the additional <code>src_prefix</code> and <code>tgt_prefix</code> parameters in its data configuration:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">corpus_1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">path_src</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> toy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">ende/src</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">train1.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">path_tgt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> toy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">ende/tgt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">train1.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">transforms</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">prefix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">weight</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">src_prefix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> __some_src_prefix__</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">tgt_prefix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> __some_tgt_prefix__</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>At inference if you want to use the target prefix feature to prefix your target segment with a unique prefix (as opposed to a target prefix coming from a line-by-line file)
you need to set your yaml file as follow (example given with a target language as in the NLLB-200 case):</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">tgt_prefix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;spa_Latn&quot;</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">tgt_file_prefix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="add-custom-suffix-to-examples">Add custom suffix to examples<a href="#add-custom-suffix-to-examples" class="hash-link" aria-label="Direct link to Add custom suffix to examples" title="Direct link to Add custom suffix to examples">‚Äã</a></h4>
<p>Transform name: <code>suffix</code></p>
<p>Class: <code>eole.transforms.misc.SuffixTransform</code></p>
<p>For each dataset that the <code>suffix</code> transform is applied to, you can set the additional <code>src_suffix</code> and <code>tgt_suffix</code> parameters in its data configuration:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">corpus_1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">path_src</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> toy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">ende/src</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">train1.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">path_tgt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> toy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">ende/tgt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">train1.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">transforms</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">suffix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">weight</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">src_suffix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> __some_src_suffix__</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">tgt_suffix</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> __some_tgt_suffix__</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="convert-examples-to-uppercase">Convert examples to uppercase<a href="#convert-examples-to-uppercase" class="hash-link" aria-label="Direct link to Convert examples to uppercase" title="Direct link to Convert examples to uppercase">‚Äã</a></h4>
<p>Transform name: <code>uppercase</code></p>
<p>Class: <code>eole.transforms.uppercase.UpperCaseTransform</code></p>
<p>Converts source and target (if present) examples to uppercase so the model can learn better to translate
sentences in all caps. This transform normalizes the examples so the uppercased strings are stripped from
any diacritics and accents. Usually this is desirable for most languages, although there are few exceptions.</p>
<p>The following option can be added to the main configuration (same ratio for all dataset with this transform):</p>
<ul>
<li><code>upper_corpus_ratio</code>: ratio of the corpus that will be transformed to uppercase (default: 0.01);</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="normalize-punctuation">Normalize punctuation<a href="#normalize-punctuation" class="hash-link" aria-label="Direct link to Normalize punctuation" title="Direct link to Normalize punctuation">‚Äã</a></h4>
<p>Transform name: <code>normalize</code></p>
<p>Class: <code>eole.transforms.normalize.NormalizeTransform</code></p>
<p>Normalizes source and target (if present) examples using the same rules as Moses punctuation normalizer.</p>
<p>The following options can be added to the configuration of each dataset:</p>
<ul>
<li><code>src_lang</code>: en, de, cz/cs, fr (default=&#x27;&#x27;)</li>
<li><code>tgt_lang</code>: en, de, cz/cs, fr (default=&#x27;&#x27;)</li>
<li><code>penn</code>: Penn substitution (default=True)</li>
<li><code>norm_quote_commas</code>: Normalize quotations and commas (default=True)</li>
<li><code>norm_numbers</code>: Normalize numbers (default=True)</li>
<li><code>pre_replace_unicode_punct</code>: Replace unicode punct (default=False)</li>
<li><code>post_remove_control_chars</code>: Remove control chars (default=False)</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="clean-dataset">Clean dataset<a href="#clean-dataset" class="hash-link" aria-label="Direct link to Clean dataset" title="Direct link to Clean dataset">‚Äã</a></h4>
<p>Transform name: <code>clean</code></p>
<p>Class: <code>eole.transforms.clean.CleanTransform</code></p>
<p>Cleans source and target (if present) examples using a set of rules.</p>
<p>The following options can be added to the configuration of each dataset:</p>
<ul>
<li><code>src_eq_tgt</code>: Remove example when source=target (default=True)</li>
<li><code>same_char</code>: Remove example if the same char is repeated 4 times (default=True)</li>
<li><code>same_word</code>: Remove example if the same word is repeated 3 times (default=True)</li>
<li><code>script_ok</code>: Remove example which contains chars that do not belong to these scripts (default=[&#x27;Latin&#x27;, &#x27;Common&#x27;])</li>
<li><code>script_nok</code>: Remove example which contains chars that belong to these scripts  (default=[])</li>
<li><code>src_tgt_ratio</code>: Remove example for which src/tgt ration is &lt;1/ratio or &gt;ratio (default=2)</li>
<li><code>avg_tok_min</code>: Remove example for which the average token length is &lt; X (default=3)</li>
<li><code>avg_tok_max</code>: Remove example for which the average token length is &gt; X (default=20)</li>
<li><code>lang_id</code>: Remove example for which detected language is not in [] (default=[&#x27;en&#x27;, &#x27;fr&#x27;])</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="context--doc-aware-transform">Context / Doc aware transform<a href="#context--doc-aware-transform" class="hash-link" aria-label="Direct link to Context / Doc aware transform" title="Direct link to Context / Doc aware transform">‚Äã</a></h4>
<p>Transform name: <code>docify</code></p>
<p>Class: <code>eole.transforms.docify.DocifyTransform</code></p>
<p>Concatenates several segments into one, separated with a delimiter.</p>
<p>Pre-requisite:</p>
<p>Dataset must be &quot;Docs&quot; separated by an empty line which will make clear a story ends at this empty line.</p>
<p>The following options can be added to the main configuration (same options for all dataset with this transform):</p>
<ul>
<li><code>doc_length</code>: max token to be concatenated (default=200)</li>
<li><code>max_context</code>: number of delimiter (default=1 , ie 2 segments concatenated)</li>
</ul>
<p>When working with several workers, this require some precaution in order to make sure &quot;doc&quot; are read linearly.</p>
<p><code>max_context + 1</code> needs to be a multiple of <code>stride</code> = <code>Number of gpu x num_workers</code></p>
<p>Example: <code>max_context=1</code> and 1 GPU, then num_workers must be 2 or 4.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="augment-source-segments-with-fuzzy-matches-for-neural-fuzzy-repair">Augment source segments with fuzzy matches for Neural Fuzzy Repair<a href="#augment-source-segments-with-fuzzy-matches-for-neural-fuzzy-repair" class="hash-link" aria-label="Direct link to Augment source segments with fuzzy matches for Neural Fuzzy Repair" title="Direct link to Augment source segments with fuzzy matches for Neural Fuzzy Repair">‚Äã</a></h4>
<p>Transform name: <code>fuzzymatch</code></p>
<p>Class: <code>eole.transforms.fuzzymatch.FuzzyMatchTransform</code></p>
<p>Augments source segments with fuzzy matches for Neural Fuzzy Repair, as described in <a href="https://aclanthology.org/P19-1175" target="_blank" rel="noopener noreferrer">Neural Fuzzy Repair: Integrating Fuzzy Matches into Neural Machine Translation</a>. Currently, the transform augments source segments with only a single fuzzy match.
The Translation Memory (TM) format should be a flat text file, with each line containing the source and the target segment separated by a delimiter. As fuzzy matching during training is computational intensive, we offer some advice to achieve good performance and minimize overhead:</p>
<ul>
<li>Depending on your system&#x27;s specs, you may have to experiment with the options <code>bucket_size</code>, <code>bucket_size_init</code>, and <code>bucket_size_increment</code>;</li>
<li>You should increase the <code>num_workers</code> and <code>prefetch_factor</code> so your GPU does not have to wait for the batches to be augmented with fuzzy matches;</li>
<li>Try to use a sensible Translation Memory size. 200k-250k translation units should be enough for yielding a sufficient number of matches;</li>
<li>Although the transform performs some basic filtering both in the TM and in the corpus for very short or very long segments, some examples may still be long enough, so you should increase a bit the <code>src_seq_length</code>;</li>
<li>Currently, when using <code>n_sample</code>, examples are always processed one by one and not in batches.</li>
</ul>
<p>The following options can be added to the main configuration (valid for all datasets using this transform):</p>
<ul>
<li><code>tm_path</code>: The path to the Translation Memory text file;</li>
<li><code>fuzzy_corpus_ratio</code>: Ratio of corpus to augment with fuzzy matches (default: 0.1);</li>
<li><code>fuzzy_threshold</code>: The fuzzy matching threshold (default: 70);</li>
<li><code>tm_delimiter</code>: The delimiter used in the flat text TM (default: &quot;\t&quot;);</li>
<li><code>fuzzy_token</code>: The fuzzy token to be added with the matches (default: &quot;ÔΩüfuzzyÔΩ†&quot;);</li>
<li><code>fuzzymatch_min_length</code>: Min length for TM entries and examples to match (default: 4);</li>
<li><code>fuzzymatch_max_length</code>: Max length for TM entries and examples to match (default: 70).</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="augment-source-and-target-segments-with-inline-tags">Augment source and target segments with inline tags<a href="#augment-source-and-target-segments-with-inline-tags" class="hash-link" aria-label="Direct link to Augment source and target segments with inline tags" title="Direct link to Augment source and target segments with inline tags">‚Äã</a></h4>
<p>Transform name: <code>inlinetags</code></p>
<p>Class: <code>eole.transforms.inlinetags.InlineTagsTransform</code></p>
<p>Augments source and target segments with inline tags (placeholders). The transform adds 2 kind of tags, paired tags (an opening and a closing tag) and isolated (standalone) tags, and requires a tab-delimited dictionary text file with source and target terms and phrases. A dictionary with 20-30k entries is recommended. User-defined tags must include the number placeholder #, e.g. &quot;ÔΩüuser_start_tag_#ÔΩ†&quot;.</p>
<p>The following options can be added to the main configuration (valid for all datasets using this transform):</p>
<ul>
<li><code>tags_dictionary_path</code>: The path to the dictionary text file;</li>
<li><code>tags_corpus_ratio</code>: Ratio of corpus to augment with inline tags (default: 0.1);</li>
<li><code>max_tags</code>: Maximum number of tags that can be added to a single sentence. (default: 12);</li>
<li><code>paired_stag</code>: The format of an opening paired inline tag. Must include the character # (default: &quot;ÔΩüph_#_begÔΩ†&quot;);</li>
<li><code>paired_etag</code>: The format of a closing paired inline tag. Must include the character # (default: &quot;ÔΩüph_#_endÔΩ†&quot;);</li>
<li><code>isolated_tag</code>: The format of an isolated inline tag. Must include the character # (default: &quot;ÔΩüph_#_stdÔΩ†&quot;);</li>
<li><code>src_delimiter</code>: Any special token used for augmented src sentences (default: &quot;ÔΩüfuzzyÔΩ†&quot;);</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="make-the-model-learn-to-use-terminology">Make the model learn to use terminology<a href="#make-the-model-learn-to-use-terminology" class="hash-link" aria-label="Direct link to Make the model learn to use terminology" title="Direct link to Make the model learn to use terminology">‚Äã</a></h4>
<p>Transform name: <code>terminology</code></p>
<p>Class: <code>eole.transforms.terminology.TerminologyTransform</code></p>
<p>Augments source segments with terms so the model can learn to use user-provided terms at inference. It requires a dictionary with source and target terms, delimited with a tab. The transform uses Spacy&#x27;s lemmatization facilities in order to a) solve the word inflection problem when searching for terms in any form, and b) make the model inflect correctly most target terms at inference. The lemmatization is applied at the dictionary entries and also at the source and target examples, and the term searches during training are performed on the lemmatized examples.
The format of a processed segment augmented with terms is as follows:
<code>This is an ÔΩüsrc_term_startÔΩ† augmented ÔΩütgt_term_startÔΩ† target_lemma_for_augmented ÔΩütgt_term_endÔΩ† example.</code>
The following options can be added to the main configuration (valid for all datasets using this transform):</p>
<ul>
<li><code>termbase_path</code>: The path to the dictionary text file;</li>
<li><code>src_spacy_language_model</code>: Name of the spacy language model for the source corpus;</li>
<li><code>tgt_spacy_language_model</code>: Name of the spacy language model for the target corpus;</li>
<li><code>term_corpus_ratio</code>: Ratio of corpus to augment with terms # (default: 0.3);</li>
<li><code>term_example_ratio</code>: Max terms allowed in an example # (default: 0.2);</li>
<li><code>src_term_stoken</code>: The source term start token # (default: &quot;ÔΩüsrc_term_startÔΩ†&quot;);</li>
<li><code>tgt_term_stoken</code>: The target term start token # (default: &quot;ÔΩütgt_term_startÔΩ†&quot;);</li>
<li><code>tgt_term_etoken</code>: The target term end token # (default: &quot;ÔΩütgt_term_endÔΩ†&quot;);</li>
<li><code>term_source_delimiter</code>: Any special token used for augmented src sentences. The default is the fuzzy token used in the FuzzyMatch transform # (default: &quot;ÔΩüfuzzyÔΩ†&quot;);</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tokenization">Tokenization<a href="#tokenization" class="hash-link" aria-label="Direct link to Tokenization" title="Direct link to Tokenization">‚Äã</a></h3>
<p>Common options for the tokenization transforms are the following:</p>
<ul>
<li><code>src_subword_model</code>: path of source side (or both if shared) subword model;</li>
<li><code>tgt_subword_model</code>: path of target side subword model;</li>
<li><code>src_subword_nbest</code>: number of candidates for subword regularization (sentencepiece), source side;</li>
<li><code>tgt_subword_nbest</code>: number of candidates for subword regularization (sentencepiece), target_side;</li>
<li><code>src_subword_alpha</code>: smoothing parameter for sentencepiece regularization / dropout probability for BPE, source side;</li>
<li><code>tgt_subword_alpha</code>: smoothing parameter for sentencepiece regularization / dropout probability for BPE, target side.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="opennmt-tokenizer"><a href="https://github.com/opennmt/Tokenizer" target="_blank" rel="noopener noreferrer">OpenNMT Tokenizer</a><a href="#opennmt-tokenizer" class="hash-link" aria-label="Direct link to opennmt-tokenizer" title="Direct link to opennmt-tokenizer">‚Äã</a></h4>
<p>Transform name: <code>onmt_tokenize</code></p>
<p>Class: <code>eole.transforms.tokenize.OnmtTokenizerTransform</code></p>
<p>Additional options are available:</p>
<ul>
<li><code>src_subword_type</code>: type of subword model for source side (from <code>[&quot;none&quot;, &quot;sentencepiece&quot;, &quot;bpe&quot;]</code>);</li>
<li><code>tgt_subword_type</code>: type of subword model for target side (from <code>[&quot;none&quot;, &quot;sentencepiece&quot;, &quot;bpe&quot;]</code>);</li>
<li><code>src_onmttok_kwargs</code>: additional kwargs for pyonmttok Tokenizer class, source side;</li>
<li><code>tgt_onmttok_kwargs</code>: additional kwargs for pyonmttok Tokenizer class, target side.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sentencepiece"><a href="https://github.com/google/sentencepiece" target="_blank" rel="noopener noreferrer">SentencePiece</a><a href="#sentencepiece" class="hash-link" aria-label="Direct link to sentencepiece" title="Direct link to sentencepiece">‚Äã</a></h4>
<p>Transform name: <code>sentencepiece</code></p>
<p>Class: <code>eole.transforms.tokenize.SentencePieceTransform</code></p>
<p>The <code>src_subword_model</code> and <code>tgt_subword_model</code> should be valid sentencepiece models.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="bpe-subword-nmt"><a href="https://github.com/rsennrich/subword-nmt" target="_blank" rel="noopener noreferrer">BPE subword-nmt</a><a href="#bpe-subword-nmt" class="hash-link" aria-label="Direct link to bpe-subword-nmt" title="Direct link to bpe-subword-nmt">‚Äã</a></h4>
<p>Transform name: <code>bpe</code></p>
<p>Class: <code>eole.transforms.tokenize.BPETransform</code></p>
<p>The <code>src_subword_model</code> and <code>tgt_subword_model</code> should be valid BPE models.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="bart-style-noise">BART-style noise<a href="#bart-style-noise" class="hash-link" aria-label="Direct link to BART-style noise" title="Direct link to BART-style noise">‚Äã</a></h3>
<p>BART-style noise is composed of several parts, as described in <a href="https://arxiv.org/abs/1910.13461" target="_blank" rel="noopener noreferrer">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a>.</p>
<p>These different types of noise can be controlled with the following options:</p>
<ul>
<li><code>permute_sent_ratio</code>: proportion of sentences to permute (default boundaries are &quot;.&quot;, &quot;?&quot; and &quot;!&quot;);</li>
<li><code>rotate_ratio</code>: proportion of inputs to permute;</li>
<li><code>insert_ratio</code>: proportion of additional random tokens to insert;</li>
<li><code>random_ratio</code>: proportion of tokens to replace with random;</li>
<li><code>mask_ratio</code>: proportion of words/subwords to mask;</li>
<li><code>mask_length</code>: length of masking window (from <code>[&quot;subword&quot;, &quot;word&quot;, &quot;span-poisson&quot;]</code>);</li>
<li><code>poisson_lambda</code>: $\lambda$ value for Poisson distribution to sample span length (in the case of <code>mask_length</code> set to <code>span-poisson</code>);</li>
<li><code>replace_length</code>: when masking N tokens, replace with 0, 1, &quot; &quot;or N tokens. (set to -1 for N).</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="switchout-and-sampling">SwitchOut and sampling<a href="#switchout-and-sampling" class="hash-link" aria-label="Direct link to SwitchOut and sampling" title="Direct link to SwitchOut and sampling">‚Äã</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="switchout"><a href="https://arxiv.org/abs/1808.07512" target="_blank" rel="noopener noreferrer">SwitchOut</a><a href="#switchout" class="hash-link" aria-label="Direct link to switchout" title="Direct link to switchout">‚Äã</a></h4>
<p>Transform name: <code>switchout</code></p>
<p>Class: <code>eole.transforms.sampling.SwitchOutTransform</code></p>
<p>Options:</p>
<ul>
<li><code>switchout_temperature</code>: sampling temperature for SwitchOut.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="drop-some-tokens">Drop some tokens<a href="#drop-some-tokens" class="hash-link" aria-label="Direct link to Drop some tokens" title="Direct link to Drop some tokens">‚Äã</a></h4>
<p>Transform name: <code>tokendrop</code></p>
<p>Class: <code>eole.transforms.sampling.TokenDropTransform</code></p>
<p>Options:</p>
<ul>
<li><code>tokendrop_temperature</code>: sampling temperature for token deletion.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="mask-some-tokens">Mask some tokens<a href="#mask-some-tokens" class="hash-link" aria-label="Direct link to Mask some tokens" title="Direct link to Mask some tokens">‚Äã</a></h4>
<p>Transform name: <code>tokenmask</code></p>
<p>Class: <code>eole.transforms.sampling.TokenMaskTransform</code></p>
<p>Options:</p>
<ul>
<li><code>tokenmask_temperature</code>: sampling temperature for token masking.</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/eole-nlp/eole/tree/main/docs/docs/concepts/transforms.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/eole/docs/concepts/weighting"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Dataset Weighting</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/eole/docs/category/frequently-asked-questions"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Frequently Asked Questions</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#transform-types" class="table-of-contents__link toc-highlight">Transform Types</a></li><li><a href="#general-purpose" class="table-of-contents__link toc-highlight">General purpose</a></li><li><a href="#tokenization" class="table-of-contents__link toc-highlight">Tokenization</a></li><li><a href="#bart-style-noise" class="table-of-contents__link toc-highlight">BART-style noise</a></li><li><a href="#switchout-and-sampling" class="table-of-contents__link toc-highlight">SwitchOut and sampling</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/eole/docs/">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="footer__link-item">Source<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">EOLE is an open-source toolkit and is licensed under the MIT license.</div></div></div></footer></div>
</body>
</html>