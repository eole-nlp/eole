<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.0">
<title data-rh="true">EOLE | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://eole-nlp.github.io/eole/docs/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="EOLE | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress"><meta data-rh="true" name="description" content="Documentation"><meta data-rh="true" property="og:description" content="Documentation"><link data-rh="true" rel="icon" href="/eole/img/eole-logo.ico"><link data-rh="true" rel="canonical" href="https://eole-nlp.github.io/eole/docs/"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/" hreflang="en"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/" hreflang="x-default"><link rel="stylesheet" href="/eole/assets/css/styles.0e100862.css">
<script src="/eole/assets/js/runtime~main.0169c973.js" defer="defer"></script>
<script src="/eole/assets/js/main.fc765e27.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/eole/"><div class="navbar__logo"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/eole/docs/">Docs</a><a class="navbar__item navbar__link" href="/eole/docs/reference/index">Reference</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/eole/docs/">EOLE</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/quickstart">Quickstart</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/eole/docs/category/key-concepts">Key Concepts</a><button aria-label="Expand sidebar category &#x27;Key Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/eole/docs/category/frequently-asked-questions">Frequently Asked Questions</a><button aria-label="Expand sidebar category &#x27;Frequently Asked Questions&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/eole/docs/category/recipes">Recipes</a><button aria-label="Expand sidebar category &#x27;Recipes&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/contributing">Contributors</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/eole/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">EOLE</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>EOLE</h1>
<p><a href="https://eole-nlp.github.io/eole" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/docs-latest-blue.svg" alt="Documentation" class="img_ev3q"></a></p>
<p>Open language modeling toolkit based on <a href="https://pytorch.org" target="_blank" rel="noopener noreferrer">PyTorch</a> initially spun-off of OpenNMT-py</p>
<p>We aim to maintain the research-friendly approach of the original project while including latest architectures (LLMs) and various other techniques.
Our goal is to provide a comprehensive yet compact and modular codebase for experimenting with various types of language models (encoder, decoder, seq2seq).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="latest-developments">Latest developments<a href="#latest-developments" class="hash-link" aria-label="Direct link to Latest developments" title="Direct link to Latest developments">‚Äã</a></h2>
<ul>
<li><strong>Mistral-3.1-24B-instruct</strong> support (text and image input)</li>
<li><strong>Pure-BF16 Training</strong> thanks to <a href="https://arxiv.org/pdf/2010.06192" target="_blank" rel="noopener noreferrer">Kahan Summation</a> implemented <a href="https://optimi.benjaminwarner.dev/kahan_summation/" target="_blank" rel="noopener noreferrer">here</a></li>
<li><strong>Web-based (Google translator-like) interface</strong> featuring the latest EuroLLM-8B-Instruct LLM: read more <a href="https://github.com/eole-nlp/eole/tree/main/recipes/eurollm" target="_blank" rel="noopener noreferrer">here</a></li>
<li><strong>Estimator layer</strong> which enables to rescore multiple beams in the same model. Read article <a href="https://medium.com/p/05b00b271a47" target="_blank" rel="noopener noreferrer">here</a> and <a href="https://medium.com/p/7dccfe167814" target="_blank" rel="noopener noreferrer">here</a></li>
<li><strong>Support Hugging Face Tokenizers</strong> for better compatiblity</li>
<li><strong>New recipes</strong> for TowerInstruct-llama2 and TowerInstruct-Mistral</li>
<li><strong>Support latest models</strong> for Llama3.x, Gemma2, Pixtral</li>
<li><strong>Replicate CometKiwi(XL/XXL)</strong> Encoder+Estimator models</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="work-completed">Work completed<a href="#work-completed" class="hash-link" aria-label="Direct link to Work completed" title="Direct link to Work completed">‚Äã</a></h2>
<p>We have made significant progress in several areas:</p>
<ul>
<li><strong>Configuration Management</strong>: Streamlined through <a href="https://docs.pydantic.dev" target="_blank" rel="noopener noreferrer">pydantic</a> models.</li>
<li><strong>Command Line Entry Points</strong>: Improved using structured subparsers for better organization.</li>
<li><strong>Reproducible Recipes</strong>: Provided for widely used models and tasks, ensuring consistency and reliability.</li>
<li><strong>Core API Simplification</strong>: Refined around the new configuration objects for ease of use.</li>
<li><strong>Revamped Fast API based server</strong>: see above example with EuroLLM-9B-Instruct</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="future-directions">Future Directions<a href="#future-directions" class="hash-link" aria-label="Direct link to Future Directions" title="Direct link to Future Directions">‚Äã</a></h3>
<p>There are still several exciting avenues to explore:</p>
<ul>
<li><strong>Further Simplification and Refactoring</strong>: Continue enhancing the codebase for clarity and efficiency.</li>
<li><strong>Documentation</strong>: Enhance and expand the documentation for better user guidance.</li>
<li><strong>Test Coverage</strong>: Improve testing to ensure code reliability and performance.</li>
<li><strong>Logging Enhancements</strong>: Implement more sophisticated logging mechanisms.</li>
<li><strong>Broader Model Support</strong>: Extend support to include a wider range of open models, potentially multi-modal.</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-features">Key Features<a href="#key-features" class="hash-link" aria-label="Direct link to Key Features" title="Direct link to Key Features">‚Äã</a></h2>
<ul>
<li><strong>Versatile Training and Inference</strong>: Train from scratch, finetune, and infer models of various architectures including Transformer Encoder/Decoder/EncoderDecoder and RNN EncoderDecoder.</li>
<li><strong>Dynamic Data Transforms</strong>: Apply on-the-fly transformations in the dataloading logic for both training and inference.</li>
<li><strong>Comprehensive LLM Support</strong>: Includes converters for Llama, Mistral, Phi, Gemma ...</li>
<li><strong>Advanced Quantization</strong>: Support for 8-bit and 4-bit quantization, along with LoRA adapters, with or without checkpointing, as well as mixed precision (FP16).</li>
<li><strong>Efficient Finetuning</strong>: Finetune 7B and 13B models on a single RTX 24GB GPU using 4-bit quantization.</li>
<li><strong>Flexible Inference</strong>: Perform inference in 4-bit or 8-bit using the same layer quantization methods as in finetuning.</li>
<li><strong>Tensor Parallelism</strong>: Enable tensor parallelism for both training and inference when models exceed the memory capacity of a single GPU.</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="setup">Setup<a href="#setup" class="hash-link" aria-label="Direct link to Setup" title="Direct link to Setup">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-docker">Using Docker<a href="#using-docker" class="hash-link" aria-label="Direct link to Using Docker" title="Direct link to Using Docker">‚Äã</a></h3>
<p>To facilitate setup and reproducibility, we provide Docker images via the GitHub Container Registry: <a href="https://github.com/eole-nlp/eole/pkgs/container/eole" target="_blank" rel="noopener noreferrer">EOLE Docker Images</a>.</p>
<p>You can customize the workflow and build your own images based on specific needs using <code>build.sh</code> and <code>Dockerfile</code> in the <code>docker</code> directory of the repository.</p>
<p>To pull the Docker image:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker pull ghcr.io/eole-nlp/eole:0.2.0-torch2.6.0-ubuntu22.04-cuda12.6</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Example one-liner to run a container and open a bash shell within it:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker run --rm -it --runtime=nvidia ghcr.io/eole-nlp/eole:0.2.0-torch2.6.0-ubuntu22.04-cuda12.6</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<blockquote>
<p><strong>Note</strong>: Ensure you have the <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html" target="_blank" rel="noopener noreferrer">Nvidia Container Toolkit</a> (formerly nvidia-docker) installed to take advantage of CUDA/GPU features.</p>
</blockquote>
<p>Depending on your needs, you can add various flags:</p>
<ul>
<li><code>-p 5000:5000</code>: Forward an exposed port from your container to your host.</li>
<li><code>-v /some/local/directory:/some/container/directory</code>: Mount a local directory to a container directory.</li>
<li><code>--entrypoint some_command</code>: Run a specific command as the container entry point (instead of the default bash shell).</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="installing-locally">Installing Locally<a href="#installing-locally" class="hash-link" aria-label="Direct link to Installing Locally" title="Direct link to Installing Locally">‚Äã</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="requirements">Requirements<a href="#requirements" class="hash-link" aria-label="Direct link to Requirements" title="Direct link to Requirements">‚Äã</a></h4>
<ul>
<li>Python &gt;= 3.10</li>
<li>PyTorch &gt;= 2.5 &lt; 2.8</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="installation-from-source">Installation from Source<a href="#installation-from-source" class="hash-link" aria-label="Direct link to Installation from Source" title="Direct link to Installation from Source">‚Äã</a></h4>
<p>To install from source:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/eole-nlp/eole</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd eole</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install -e .</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="installation-from-pypi">Installation from PyPI<a href="#installation-from-pypi" class="hash-link" aria-label="Direct link to Installation from PyPI" title="Direct link to Installation from PyPI">‚Äã</a></h4>
<p>Installation from PyPI will be available soon.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="notes">Notes<a href="#notes" class="hash-link" aria-label="Direct link to Notes" title="Direct link to Notes">‚Äã</a></h4>
<p>If you encounter a <code>MemoryError</code> during installation, try using <code>pip</code> with the <code>--no-cache-dir</code> option.</p>
<p>(Optional) Some advanced features (e.g., pretrained models or specific transforms) require extra packages. Install them with:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install -r requirements.opt.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="manual-installation-of-some-dependencies">Manual Installation of Some Dependencies<a href="#manual-installation-of-some-dependencies" class="hash-link" aria-label="Direct link to Manual Installation of Some Dependencies" title="Direct link to Manual Installation of Some Dependencies">‚Äã</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="flash-attention">Flash Attention<a href="#flash-attention" class="hash-link" aria-label="Direct link to Flash Attention" title="Direct link to Flash Attention">‚Äã</a></h4>
<p>To use <a href="https://github.com/Dao-AILab/flash-attention#installation-and-features" target="_blank" rel="noopener noreferrer">Flash Attention</a>, install it manually:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install flash-attn --no-build-isolation</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="awq">AWQ<a href="#awq" class="hash-link" aria-label="Direct link to AWQ" title="Direct link to AWQ">‚Äã</a></h4>
<p>For inference or quantizing an AWQ model, AutoAWQ is required. Install it with:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install autoawq</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For more details, refer to <a href="https://github.com/casper-hansen/AutoAWQ" target="_blank" rel="noopener noreferrer">AutoAWQ</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="notes-on-mixed-precision-or-low-precision-training">Notes on Mixed-precision or Low precision Training<a href="#notes-on-mixed-precision-or-low-precision-training" class="hash-link" aria-label="Direct link to Notes on Mixed-precision or Low precision Training" title="Direct link to Notes on Mixed-precision or Low precision Training">‚Äã</a></h2>
<p>Until Feb 25, we used torch optimizers with or without AMP (mixed precision) or &quot;fusedadam&quot; which was an old implementation of Apex/Nvidia using FP16 with dynamic loss scaling and without FP32 master weights.
As of 0.2 &quot;fusedadam&quot; is deprecated and we implemented pure-BF16 training.</p>
<p>As a result, config flags are now:</p>
<p>For FP16-amp or BF16-amp training (using pytorch optimizers and amp implementation)</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">compute_dtype: fp16 or bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">use_amp: true</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optim: adam or adamw</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Special note: even though it may not be logical, we still use the torch GradScaler in BF16-AMP. Even if the BF16 range is similar to FP32, scaling prevents from underflowing.
We tested BF16-AMP without the GradScaler and it does not give good results.</p>
<p>For pure-bf16 training (using torch-optimi and kahan summation)</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">compute_dtype: bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">use_amp: true</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optim: adam or adamw</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Pure-BF16 training is faster than AMP and the memory footprint is reduced (master weights are kept in BF16 vs FP32). However Kahan Summation is not magical, results are good but not as good as AMP.
Use this feature mainly when memory footprint is an issue with LLMs.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="contributing">Contributing<a href="#contributing" class="hash-link" aria-label="Direct link to Contributing" title="Direct link to Contributing">‚Äã</a></h2>
<p>We love contributions! Please look at issues marked with the <a href="https://github.com/eole-nlp/eole/issues?q=is%3Aissue+is%3Aopen+label%3A%22contributions+welcome%22" target="_blank" rel="noopener noreferrer">contributions welcome</a> tag.</p>
<p>Before raising an issue, make sure you read the requirements and the <a href="https://eole-nlp.github.io/eole" target="_blank" rel="noopener noreferrer">Full Documentation</a>. You can also check if a <a href="https://github.com/eole-nlp/eole/tree/main/recipes" target="_blank" rel="noopener noreferrer">Recipe</a> fits your use case.</p>
<p>Unless there is a bug, please use the <a href="https://github.com/eole-nlp/eole/discussions" target="_blank" rel="noopener noreferrer">Discussions</a> tab to ask questions or propose new topics/features.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/eole-nlp/eole/tree/main/docs/docs/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--next" href="/eole/docs/quickstart"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Quickstart</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#latest-developments" class="table-of-contents__link toc-highlight">Latest developments</a></li><li><a href="#work-completed" class="table-of-contents__link toc-highlight">Work completed</a><ul><li><a href="#future-directions" class="table-of-contents__link toc-highlight">Future Directions</a></li></ul></li><li><a href="#key-features" class="table-of-contents__link toc-highlight">Key Features</a></li><li><a href="#setup" class="table-of-contents__link toc-highlight">Setup</a><ul><li><a href="#using-docker" class="table-of-contents__link toc-highlight">Using Docker</a></li><li><a href="#installing-locally" class="table-of-contents__link toc-highlight">Installing Locally</a></li><li><a href="#manual-installation-of-some-dependencies" class="table-of-contents__link toc-highlight">Manual Installation of Some Dependencies</a></li></ul></li><li><a href="#notes-on-mixed-precision-or-low-precision-training" class="table-of-contents__link toc-highlight">Notes on Mixed-precision or Low precision Training</a></li><li><a href="#contributing" class="table-of-contents__link toc-highlight">Contributing</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/eole/docs/">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="footer__link-item">Source<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">EOLE is an open-source toolkit and is licensed under the MIT license.</div></div></div></footer></div>
</body>
</html>