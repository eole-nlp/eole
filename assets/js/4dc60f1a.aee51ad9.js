"use strict";(self.webpackChunkdocusaurus_tsx=self.webpackChunkdocusaurus_tsx||[]).push([[7748],{2224:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>s,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>d});var o=n(4848),t=n(8453);const l={},a="Serving models with Eole",i={id:"recipes/server/README",title:"Serving models with Eole",description:"The provided example configuration allows to serve Llama3-8B-Instruct.",source:"@site/docs/recipes/server/README.md",sourceDirName:"recipes/server",slug:"/recipes/server/",permalink:"/eole/docs/recipes/server/",draft:!1,unlisted:!1,editUrl:"https://github.com/eole-nlp/eole/tree/main/docs/docs/recipes/server/README.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Pixtral",permalink:"/eole/docs/recipes/pixtral/"},next:{title:"Language Model Wiki-103",permalink:"/eole/docs/recipes/wiki_103/"}},s={},d=[{value:"Retrieve and convert model",id:"retrieve-and-convert-model",level:2},{value:"Set environment variables",id:"set-environment-variables",level:3},{value:"Option 1 - Download and convert model",id:"option-1---download-and-convert-model",level:3},{value:"Option 2 - Retrieve an already converted model from HF",id:"option-2---retrieve-an-already-converted-model-from-hf",level:3},{value:"Run server",id:"run-server",level:2},{value:"Play with the API",id:"play-with-the-api",level:2}];function c(e){const r={code:"code",h1:"h1",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(r.h1,{id:"serving-models-with-eole",children:"Serving models with Eole"}),"\n",(0,o.jsx)(r.p,{children:"The provided example configuration allows to serve Llama3-8B-Instruct."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-yaml",children:"models_root: \".\" # used only for HF downloads for now, but might override $EOLE_MODEL_DIR at some point\nmodels:\n# local model\n- id: \"llama3-8b-instruct\"\n  path: \"${EOLE_MODEL_DIR}/llama3-8b-instruct\"\n  preload: false\n  config:\n    quant_layers: ['gate_up_proj', 'down_proj', 'up_proj', 'linear_values', 'linear_query', 'linear_keys', 'final_linear']\n    quant_type: \"bnb_NF4\"\n# HF repo id, automatically downloaded to models_root\n- id: \"llama3-8b-instruct-hf\"\n  path: \"fhdz/llama3-8b-instruct\"\n  preload: true\n"})}),"\n",(0,o.jsxs)(r.p,{children:["Note: the ",(0,o.jsx)(r.code,{children:"preload"})," flag allow to load the corresponding model at server startup. See below for the two options."]}),"\n",(0,o.jsx)(r.h2,{id:"retrieve-and-convert-model",children:"Retrieve and convert model"}),"\n",(0,o.jsx)(r.h3,{id:"set-environment-variables",children:"Set environment variables"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"export EOLE_MODEL_DIR=<where_to_store_models>\nexport HF_TOKEN=<your_hf_token>\n"})}),"\n",(0,o.jsx)(r.h3,{id:"option-1---download-and-convert-model",children:"Option 1 - Download and convert model"}),"\n",(0,o.jsxs)(r.p,{children:["The first example ",(0,o.jsx)(r.code,{children:'"llama3-8b-instruct"'})," requires you to manually convert the model in your desired ",(0,o.jsx)(r.code,{children:"$EOLE_MODEL_DIR"}),"."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"eole convert HF --model_dir meta-llama/Meta-Llama-3-8B-Instruct --output $EOLE_MODEL_DIR/llama3-8b-instruct --token $HF_TOKEN\n"})}),"\n",(0,o.jsx)(r.h3,{id:"option-2---retrieve-an-already-converted-model-from-hf",children:"Option 2 - Retrieve an already converted model from HF"}),"\n",(0,o.jsxs)(r.p,{children:["The second example ",(0,o.jsx)(r.code,{children:'"llama3-8b-instruct-hf"'})," downloads a model that has already been converted, for the sake of this example."]}),"\n",(0,o.jsx)(r.h2,{id:"run-server",children:"Run server"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"eole serve -c serve.example.yaml\n"})}),"\n",(0,o.jsx)(r.h2,{id:"play-with-the-api",children:"Play with the API"}),"\n",(0,o.jsxs)(r.p,{children:["FastAPI exposes a swagger UI by default. It should be accessible via your browser at ",(0,o.jsx)(r.code,{children:"http://localhost:5000/docs"}),"."]})]})}function h(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,o.jsx)(r,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>a,x:()=>i});var o=n(6540);const t={},l=o.createContext(t);function a(e){const r=o.useContext(l);return o.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function i(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),o.createElement(l.Provider,{value:r},e.children)}}}]);