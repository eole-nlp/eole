"use strict";(self.webpackChunkdocusaurus_tsx=self.webpackChunkdocusaurus_tsx||[]).push([[1829],{5156:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>i,contentTitle:()=>d,default:()=>h,frontMatter:()=>c,metadata:()=>l,toc:()=>t});var r=o(4848),s=o(8453);const c={},d="Modules",l={id:"reference/Core API/modules",title:"Modules",description:"Embeddings",source:"@site/docs/reference/Core API/0_modules.md",sourceDirName:"reference/Core API",slug:"/reference/Core API/modules",permalink:"/eole/docs/reference/Core API/modules",draft:!1,unlisted:!1,editUrl:"https://github.com/eole-nlp/eole/tree/main/docs/docs/reference/Core API/0_modules.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{},sidebar:"apiSidebar",previous:{title:"Framework",permalink:"/eole/docs/reference/Core API/core"},next:{title:"Data Loaders",permalink:"/eole/docs/reference/Core API/dataloaders"}},i={},t=[{value:"Embeddings",id:"embeddings",level:2},{value:"<em>class</em> eole.modules.transformer_mlp.MLP(model_config, running_config=None)[source]",id:"class-eolemodulestransformer_mlpmlpmodel_config-running_confignonesource",level:3},{value:"forward(x)[source]",id:"forwardxsource",level:4},{value:"Encoders",id:"encoders",level:2},{value:"<em>class</em> eole.encoders.TransformerEncoder(model_config, running_config=None)[source]",id:"class-eoleencoderstransformerencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource",level:4},{value:"<em>class</em> eole.encoders.RNNEncoder(model_config, running_config=None)[source]",id:"class-eoleencodersrnnencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource-1",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-1",level:4},{value:"<em>class</em> eole.encoders.CNNEncoder(model_config, running_config=None)[source]",id:"class-eoleencoderscnnencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource-2",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-2",level:4},{value:"<em>class</em> eole.encoders.MeanEncoder(model_config, running_config=None)[source]",id:"class-eoleencodersmeanencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource-3",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-3",level:4},{value:"Decoders",id:"decoders",level:2},{value:"<em>class</em> eole.decoders.TransformerDecoder(model_config, running_config=None)[source]",id:"class-eoledecoderstransformerdecodermodel_config-running_confignonesource",level:3},{value:"forward(emb, **kwargs)[source]",id:"forwardemb-kwargssource",level:4},{value:"<em>class</em> eole.decoders.rnn_decoder.RNNDecoderBase(model_config, running_config=None)[source]",id:"class-eoledecodersrnn_decoderrnndecoderbasemodel_config-running_confignonesource",level:3},{value:"forward(emb, enc_out, src_len=None, step=None, **kwargs)[source]",id:"forwardemb-enc_out-src_lennone-stepnone-kwargssource",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-4",level:4},{value:"init_state(**kwargs)[source]",id:"init_statekwargssource",level:4},{value:"<em>class</em> eole.decoders.StdRNNDecoder(model_config, running_config=None)[source]",id:"class-eoledecodersstdrnndecodermodel_config-running_confignonesource",level:3},{value:"<em>class</em> eole.decoders.InputFeedRNNDecoder(model_config, running_config=None)[source]",id:"class-eoledecodersinputfeedrnndecodermodel_config-running_confignonesource",level:3},{value:"<em>class</em> eole.decoders.CNNDecoder(model_config, running_config=None)[source]",id:"class-eoledecoderscnndecodermodel_config-running_confignonesource",level:3},{value:"forward(emb, enc_out, step=None, **kwargs)[source]",id:"forwardemb-enc_out-stepnone-kwargssource",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-5",level:4},{value:"init_state(**kwargs)[source]",id:"init_statekwargssource-1",level:4},{value:"Attention",id:"attention",level:2},{value:"<em>class</em> eole.modules.structured_attention.MatrixTree(eps=1e-05)[source]",id:"class-eolemodulesstructured_attentionmatrixtreeeps1e-05source",level:3},{value:"forward(input)[source]",id:"forwardinputsource",level:4},{value:"NOTE",id:"note",level:4}];function a(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"modules",children:"Modules"}),"\n",(0,r.jsx)(n.h2,{id:"embeddings",children:"Embeddings"}),"\n",(0,r.jsxs)(n.h3,{id:"class-eolemodulestransformer_mlpmlpmodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.modules.transformer_mlp.MLP(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/transformer_mlp.py#L10-L92",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"Module"})]}),"\n",(0,r.jsx)(n.p,{children:"A two/three-layer Feed-Forward-Network."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model_config"})," \u2013 eole.config.models.ModelConfig object"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"running_config"})," \u2013 TrainingConfig or InferenceConfig derived from RunningConfig"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"forwardxsource",children:["forward(x)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/transformer_mlp.py#L63-L88",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Layer definition."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsx)(n.strong,{children:"x"})," \u2013 ",(0,r.jsx)(n.code,{children:"(batch_size, input_len, model_dim)"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Returns:"}),"\nOutput ",(0,r.jsx)(n.code,{children:"(batch_size, input_len, model_dim)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Return type:"}),"\n(FloatTensor)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"encoders",children:"Encoders"}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoleencoderstransformerencodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.encoders.TransformerEncoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/transformer.py#L81-L152",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"EncoderBase"})]}),"\n",(0,r.jsx)(n.p,{children:"The Transformer encoder from \u201cAttention is All You Need\u201d\n[]"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model_config"})," (",(0,r.jsx)(n.em,{children:"eole.config.TransformerEncoderConfig"}),") \u2013 full encoder config"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"embeddings"})," (",(0,r.jsx)(n.em,{children:"eole.modules.Embeddings"}),") \u2013 embeddings to use, should have positional encodings"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"running_config"})," (",(0,r.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Returns:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["enc_out ",(0,r.jsx)(n.code,{children:"(batch_size, src_len, model_dim)"})]}),"\n",(0,r.jsx)(n.li,{children:"encoder final state: None in the case of Transformer"}),"\n",(0,r.jsxs)(n.li,{children:["src_len ",(0,r.jsx)(n.code,{children:"(batch_size)"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Return type:"}),"\n(torch.FloatTensor, torch.FloatTensor)"]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"forwardemb-masknonesource",children:["forward(emb, mask=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/transformer.py#L130-L148",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.code,{children:"EncoderBase.forward()"})]}),"\n",(0,r.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/transformer.py#L122-L128",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoleencodersrnnencodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.encoders.RNNEncoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/rnn_encoder.py#L8-L97",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"EncoderBase"})]}),"\n",(0,r.jsx)(n.p,{children:"A generic recurrent neural network encoder."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model_config"})," (",(0,r.jsx)(n.em,{children:"eole.config.ModelConfig"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"running_config"})," (",(0,r.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"forwardemb-masknonesource-1",children:["forward(emb, mask=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/rnn_encoder.py#L46-L54",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.code,{children:"EncoderBase.forward()"})]}),"\n",(0,r.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-1",children:[(0,r.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/rnn_encoder.py#L41-L44",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoleencoderscnnencodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.encoders.CNNEncoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/cnn_encoder.py#L12-L53",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"EncoderBase"})]}),"\n",(0,r.jsx)(n.p,{children:"Encoder based on \u201cConvolutional Sequence to Sequence Learning\u201d\n[]."}),"\n",(0,r.jsxs)(n.h4,{id:"forwardemb-masknonesource-2",children:["forward(emb, mask=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/cnn_encoder.py#L40-L50",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.code,{children:"EncoderBase.forward()"})]}),"\n",(0,r.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-2",children:[(0,r.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/cnn_encoder.py#L31-L38",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoleencodersmeanencodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.encoders.MeanEncoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/mean_encoder.py#L6-L41",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"EncoderBase"})]}),"\n",(0,r.jsx)(n.p,{children:"A trivial non-recurrent encoder. Simply applies mean pooling."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model_config"})," (",(0,r.jsx)(n.em,{children:"eole.config.ModelConfig"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"embeddings"})," (",(0,r.jsx)(n.em,{children:"eole.modules.Embeddings"}),") \u2013 embeddings to use, should have positional encodings"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"running_config"})," (",(0,r.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"forwardemb-masknonesource-3",children:["forward(emb, mask=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/mean_encoder.py#L26-L41",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.code,{children:"EncoderBase.forward()"})]}),"\n",(0,r.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-3",children:[(0,r.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/mean_encoder.py#L20-L24",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,r.jsx)(n.h2,{id:"decoders",children:"Decoders"}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoledecoderstransformerdecodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.decoders.TransformerDecoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/transformer_decoder.py#L136-L261",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"TransformerDecoderBase"})]}),"\n",(0,r.jsx)(n.p,{children:"The Transformer decoder from \u201cAttention is All You Need\u201d.\n[]"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model_config"})," (",(0,r.jsx)(n.em,{children:"eole.config.TransformerDecoderConfig"}),") \u2013 full decoder config"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"embeddings"})," (",(0,r.jsx)(n.em,{children:"eole.modules.Embeddings"}),") \u2013 embeddings to use, should have positional encodings"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"running_config"})," (",(0,r.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"forwardemb-kwargssource",children:["forward(emb, **kwargs)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/transformer_decoder.py#L173-L237",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Decode, possibly stepwise."}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoledecodersrnn_decoderrnndecoderbasemodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.decoders.rnn_decoder.RNNDecoderBase(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L10-L170",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"DecoderBase"})]}),"\n",(0,r.jsx)(n.p,{children:"Base recurrent attention-based decoder class."}),"\n",(0,r.jsxs)(n.p,{children:["Specifies the interface used by different decoder types\nand required by ",(0,r.jsx)(n.code,{children:"BaseModel"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"model_config"})," (",(0,r.jsx)(n.em,{children:"eole.config.DecoderConfig"}),") \u2013 full decoder config"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"running_config"})," (",(0,r.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"forwardemb-enc_out-src_lennone-stepnone-kwargssource",children:["forward(emb, enc_out, src_len=None, step=None, **kwargs)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L126-L167",children:"[source]"})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"emb"})," (",(0,r.jsx)(n.em,{children:"FloatTensor"}),") \u2013 input embeddings\n",(0,r.jsx)(n.code,{children:"(batch, tgt_len, dim)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"enc_out"})," (",(0,r.jsx)(n.em,{children:"FloatTensor"}),") \u2013 vectors from the encoder\n",(0,r.jsx)(n.code,{children:"(batch, src_len, hidden)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"src_len"})," (",(0,r.jsx)(n.em,{children:"LongTensor"}),") \u2013 the padded source lengths\n",(0,r.jsx)(n.code,{children:"(batch,)"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Returns:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["dec_outs: output from the decoder (after attn)\n",(0,r.jsx)(n.code,{children:"(batch, tgt_len, hidden)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["attns: distribution over src at each tgt\n",(0,r.jsx)(n.code,{children:"(batch, tgt_len, src_len)"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Return type:"}),"\n(FloatTensor, dict[str, FloatTensor])"]}),"\n"]}),"\n",(0,r.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-4",children:[(0,r.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L69-L76",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,r.jsxs)(n.h4,{id:"init_statekwargssource",children:["init_state(**kwargs)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L78-L106",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Initialize decoder state with last state of the encoder."}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoledecodersstdrnndecodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.decoders.StdRNNDecoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L173-L253",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.a,{href:"#eole.decoders.rnn_decoder.RNNDecoderBase",children:(0,r.jsx)(n.code,{children:"RNNDecoderBase"})})]}),"\n",(0,r.jsx)(n.p,{children:"Standard fully batched RNN decoder with attention."}),"\n",(0,r.jsxs)(n.p,{children:["Faster implementation, uses CuDNN for implementation.\nSee ",(0,r.jsx)(n.code,{children:"RNNDecoderBase"})," for options."]}),"\n",(0,r.jsx)(n.p,{children:"Based around the approach from\n\u201cNeural Machine Translation By Jointly Learning To Align and Translate\u201d\n[]"}),"\n",(0,r.jsx)(n.p,{children:"Implemented without input_feeding and currently with no coverage_attn"}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoledecodersinputfeedrnndecodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.decoders.InputFeedRNNDecoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L256-L335",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.a,{href:"#eole.decoders.rnn_decoder.RNNDecoderBase",children:(0,r.jsx)(n.code,{children:"RNNDecoderBase"})})]}),"\n",(0,r.jsx)(n.p,{children:"Input feeding based decoder."}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.code,{children:"RNNDecoderBase"})," for options."]}),"\n",(0,r.jsx)(n.p,{children:"Based around the input feeding approach from\n\u201cEffective Approaches to Attention-based Neural Machine Translation\u201d\n[]"}),"\n",(0,r.jsxs)(n.h3,{id:"class-eoledecoderscnndecodermodel_config-running_confignonesource",children:[(0,r.jsx)(n.em,{children:"class"})," eole.decoders.CNNDecoder(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L14-L125",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"DecoderBase"})]}),"\n",(0,r.jsx)(n.p,{children:"Decoder based on \u201cConvolutional Sequence to Sequence Learning\u201d\n[]."}),"\n",(0,r.jsx)(n.p,{children:"Consists of residual convolutional layers, with ConvMultiStepAttention."}),"\n",(0,r.jsxs)(n.h4,{id:"forwardemb-enc_out-stepnone-kwargssource",children:["forward(emb, enc_out, step=None, **kwargs)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L76-L121",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.code,{children:"eole.modules.RNNDecoderBase.forward()"})]}),"\n",(0,r.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-5",children:[(0,r.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L53-L59",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,r.jsxs)(n.h4,{id:"init_statekwargssource-1",children:["init_state(**kwargs)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L61-L66",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Init decoder state."}),"\n",(0,r.jsx)(n.h2,{id:"attention",children:"Attention"}),"\n",(0,r.jsxs)(n.h3,{id:"class-eolemodulesstructured_attentionmatrixtreeeps1e-05source",children:[(0,r.jsx)(n.em,{children:"class"})," eole.modules.structured_attention.MatrixTree(eps=1e-05)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/structured_attention.py#L6-L39",children:"[source]"})]}),"\n",(0,r.jsxs)(n.p,{children:["Bases: ",(0,r.jsx)(n.code,{children:"Module"})]}),"\n",(0,r.jsx)(n.p,{children:"Implementation of the matrix-tree theorem for computing marginals\nof non-projective dependency parsing. This attention layer is used\nin the paper \u201cLearning Structured Text Representations\u201d\n[]."}),"\n",(0,r.jsxs)(n.h4,{id:"forwardinputsource",children:["forward(input)",(0,r.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/structured_attention.py#L17-L39",children:"[source]"})]}),"\n",(0,r.jsx)(n.p,{children:"Define the computation performed at every call."}),"\n",(0,r.jsx)(n.p,{children:"Should be overridden by all subclasses."}),"\n",(0,r.jsx)(n.h4,{id:"note",children:"NOTE"}),"\n",(0,r.jsxs)(n.p,{children:["Although the recipe for forward pass needs to be defined within\nthis function, one should call the ",(0,r.jsx)(n.code,{children:"Module"})," instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>d,x:()=>l});var r=o(6540);const s={},c=r.createContext(s);function d(e){const n=r.useContext(c);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),r.createElement(c.Provider,{value:n},e.children)}}}]);