"use strict";(self.webpackChunkdocusaurus_tsx=self.webpackChunkdocusaurus_tsx||[]).push([[9342],{4350:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var n=s(4848),r=s(8453);const i={},a="Framework",l={id:"reference/Core API/core",title:"Framework",description:"Model",source:"@site/docs/reference/Core API/0_core.md",sourceDirName:"reference/Core API",slug:"/reference/Core API/core",permalink:"/eole/docs/reference/Core API/core",draft:!1,unlisted:!1,editUrl:"https://github.com/eole-nlp/eole/tree/main/docs/docs/reference/Core API/0_core.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{},sidebar:"apiSidebar",previous:{title:"Transforms",permalink:"/eole/docs/reference/Config/transforms"},next:{title:"Modules",permalink:"/eole/docs/reference/Core API/modules"}},o={},c=[{value:"Model",id:"model",level:2},{value:"Trainer",id:"trainer",level:2},{value:"<em>class</em> eole.utils.Statistics(loss=0, auxloss=0, n_batchs=0, n_sents=0, n_tokens=0, n_correct=0, computed_metrics=None, data_stats=None, attention_entropy=0, n_attention_samples=0)",id:"class-eoleutilsstatisticsloss0-auxloss0-n_batchs0-n_sents0-n_tokens0-n_correct0-computed_metricsnone-data_statsnone-attention_entropy0-n_attention_samples0",level:3},{value:"accuracy()",id:"accuracy",level:4},{value:"<em>static</em> all_gather_stats(stat, max_size=4096)",id:"static-all_gather_statsstat-max_size4096",level:4},{value:"<em>static</em> all_gather_stats_list(stat_list, max_size=4096)",id:"static-all_gather_stats_liststat_list-max_size4096",level:4},{value:"avg_attention_entropy()",id:"avg_attention_entropy",level:4},{value:"computed_metric(metric)",id:"computed_metricmetric",level:4},{value:"elapsed_time()",id:"elapsed_time",level:4},{value:"log_tensorboard(prefix, writer, learning_rate, patience, step)",id:"log_tensorboardprefix-writer-learning_rate-patience-step",level:4},{value:"output(step, num_steps, learning_rate, start)",id:"outputstep-num_steps-learning_rate-start",level:4},{value:"ppl()",id:"ppl",level:4},{value:"update(stat, update_n_src_tokens=False)",id:"updatestat-update_n_src_tokensfalse",level:4},{value:"xent()",id:"xent",level:4},{value:"Loss",id:"loss",level:2},{value:"Optimizer",id:"optimizer",level:2},{value:"<em>class</em> eole.utils.Optimizer(optimizer, learning_rate, learning_rate_decay_fn=None, max_grad_norm=None, use_amp=True)",id:"class-eoleutilsoptimizeroptimizer-learning_rate-learning_rate_decay_fnnone-max_grad_normnone-use_amptrue",level:3},{value:"<em>property</em> amp",id:"property-amp",level:4},{value:"backward(loss)",id:"backwardloss",level:4},{value:"<em>classmethod</em> from_config(model, config, metadata=None)",id:"classmethod-from_configmodel-config-metadatanone",level:4},{value:"learning_rate(step=None)",id:"learning_ratestepnone",level:4},{value:"step()",id:"step",level:4},{value:"<em>property</em> training_step",id:"property-training_step",level:4},{value:"zero_grad(set_to_none=True)",id:"zero_gradset_to_nonetrue",level:4},{value:"<em>class</em> eole.utils.AdaFactor(params, lr=None, beta1=0.9, beta2=0.999, eps1=1e-30, eps2=0.001, cliping_threshold=1, non_constant_decay=True, enable_factorization=True, ams_grad=True, weight_decay=0)",id:"class-eoleutilsadafactorparams-lrnone-beta109-beta20999-eps11e-30-eps20001-cliping_threshold1-non_constant_decaytrue-enable_factorizationtrue-ams_gradtrue-weight_decay0",level:3},{value:"step(closure=None)",id:"stepclosurenone",level:4}];function d(e){const t={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"framework",children:"Framework"}),"\n",(0,n.jsx)(t.h2,{id:"model",children:"Model"}),"\n",(0,n.jsx)(t.h2,{id:"trainer",children:"Trainer"}),"\n",(0,n.jsxs)(t.h3,{id:"class-eoleutilsstatisticsloss0-auxloss0-n_batchs0-n_sents0-n_tokens0-n_correct0-computed_metricsnone-data_statsnone-attention_entropy0-n_attention_samples0",children:[(0,n.jsx)(t.em,{children:"class"})," eole.utils.Statistics(loss=0, auxloss=0, n_batchs=0, n_sents=0, n_tokens=0, n_correct=0, computed_metrics=None, data_stats=None, attention_entropy=0, n_attention_samples=0)"]}),"\n",(0,n.jsxs)(t.p,{children:["Bases: ",(0,n.jsx)(t.code,{children:"object"})]}),"\n",(0,n.jsx)(t.p,{children:"Accumulator for loss statistics.\nCurrently calculates:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"accuracy"}),"\n",(0,n.jsx)(t.li,{children:"perplexity"}),"\n",(0,n.jsx)(t.li,{children:"elapsed time"}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"accuracy",children:"accuracy()"}),"\n",(0,n.jsx)(t.p,{children:"compute accuracy"}),"\n",(0,n.jsxs)(t.h4,{id:"static-all_gather_statsstat-max_size4096",children:[(0,n.jsx)(t.em,{children:"static"})," all_gather_stats(stat, max_size=4096)"]}),"\n",(0,n.jsx)(t.p,{children:"Gather a Statistics object accross multiple process/nodes"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Parameters:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"stat"}),"**(** \u2013 obj:Statistics): the statistics object to gather\naccross all processes/nodes"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"max_size"})," (",(0,n.jsx)(t.em,{children:"int"}),") \u2013 max buffer size to use"]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Returns:"}),"\nStatistics, the update stats object"]}),"\n"]}),"\n",(0,n.jsxs)(t.h4,{id:"static-all_gather_stats_liststat_list-max_size4096",children:[(0,n.jsx)(t.em,{children:"static"})," all_gather_stats_list(stat_list, max_size=4096)"]}),"\n",(0,n.jsx)(t.p,{children:"Gather a Statistics list accross all processes/nodes"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Parameters:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"stat_list"})," (list([Statistics])) \u2013 list of statistics objects to\ngather accross all processes/nodes"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"max_size"})," (",(0,n.jsx)(t.em,{children:"int"}),") \u2013 max buffer size to use"]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Returns:"}),"\nlist of updated stats"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Return type:"}),"\nour_stats(list([Statistics]))"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"avg_attention_entropy",children:"avg_attention_entropy()"}),"\n",(0,n.jsx)(t.p,{children:"compute average attention entropy"}),"\n",(0,n.jsx)(t.h4,{id:"computed_metricmetric",children:"computed_metric(metric)"}),"\n",(0,n.jsx)(t.p,{children:"check if metric(TER/BLEU) is computed and return it"}),"\n",(0,n.jsx)(t.h4,{id:"elapsed_time",children:"elapsed_time()"}),"\n",(0,n.jsx)(t.p,{children:"compute elapsed time"}),"\n",(0,n.jsx)(t.h4,{id:"log_tensorboardprefix-writer-learning_rate-patience-step",children:"log_tensorboard(prefix, writer, learning_rate, patience, step)"}),"\n",(0,n.jsx)(t.p,{children:"display statistics to tensorboard"}),"\n",(0,n.jsx)(t.h4,{id:"outputstep-num_steps-learning_rate-start",children:"output(step, num_steps, learning_rate, start)"}),"\n",(0,n.jsx)(t.p,{children:"Write out statistics to stdout."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Parameters:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"step"})," (",(0,n.jsx)(t.em,{children:"int"}),") \u2013 current step"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"n_batch"})," (",(0,n.jsx)(t.em,{children:"int"}),") \u2013 total batches"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"start"})," (",(0,n.jsx)(t.em,{children:"int"}),") \u2013 start time of step."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"ppl",children:"ppl()"}),"\n",(0,n.jsx)(t.p,{children:"compute perplexity"}),"\n",(0,n.jsx)(t.h4,{id:"updatestat-update_n_src_tokensfalse",children:"update(stat, update_n_src_tokens=False)"}),"\n",(0,n.jsx)(t.p,{children:"Update statistics by suming values with another Statistics object"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Parameters:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"stat"})," \u2013 another statistic object"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"update_n_src_tokens"})," (",(0,n.jsx)(t.em,{children:"bool"}),") \u2013 whether to update (sum) n_src_tokens\nor not"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"xent",children:"xent()"}),"\n",(0,n.jsx)(t.p,{children:"compute cross entropy"}),"\n",(0,n.jsx)(t.h2,{id:"loss",children:"Loss"}),"\n",(0,n.jsx)(t.h2,{id:"optimizer",children:"Optimizer"}),"\n",(0,n.jsxs)(t.h3,{id:"class-eoleutilsoptimizeroptimizer-learning_rate-learning_rate_decay_fnnone-max_grad_normnone-use_amptrue",children:[(0,n.jsx)(t.em,{children:"class"})," eole.utils.Optimizer(optimizer, learning_rate, learning_rate_decay_fn=None, max_grad_norm=None, use_amp=True)"]}),"\n",(0,n.jsxs)(t.p,{children:["Bases: ",(0,n.jsx)(t.code,{children:"object"})]}),"\n",(0,n.jsx)(t.p,{children:"Controller class for optimization. Mostly a thin\nwrapper for optim, but also useful for implementing\nrate scheduling beyond what is currently available.\nAlso implements necessary methods for training RNNs such\nas grad manipulations."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Parameters:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"optimizer"})," \u2013 A ",(0,n.jsx)(t.code,{children:"torch.optim.Optimizer"})," instance."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"learning_rate"})," \u2013 The initial learning rate."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"learning_rate_decay_fn"})," \u2013 An optional callable taking the current step\nas argument and return a learning rate scaling factor."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"max_grad_norm"})," \u2013 Clip gradients to this global norm."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.h4,{id:"property-amp",children:[(0,n.jsx)(t.em,{children:"property"})," amp"]}),"\n",(0,n.jsx)(t.p,{children:"True if use torch amp mix precision training."}),"\n",(0,n.jsx)(t.h4,{id:"backwardloss",children:"backward(loss)"}),"\n",(0,n.jsx)(t.p,{children:"Wrapper for backward pass. Some optimizer requires ownership of the\nbackward pass."}),"\n",(0,n.jsxs)(t.h4,{id:"classmethod-from_configmodel-config-metadatanone",children:[(0,n.jsx)(t.em,{children:"classmethod"})," from_config(model, config, metadata=None)"]}),"\n",(0,n.jsx)(t.p,{children:"Builds the optimizer from options."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Parameters:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"cls"})," \u2013 The ",(0,n.jsx)(t.code,{children:"Optimizer"})," class to instantiate."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"model"})," \u2013 The model to optimize."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"config"})," \u2013 The dict of user options."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"metadata"})," \u2013 An optional checkpoint metadata to load states from."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Returns:"}),"\nAn ",(0,n.jsx)(t.code,{children:"Optimizer"})," instance."]}),"\n"]}),"\n",(0,n.jsx)(t.h4,{id:"learning_ratestepnone",children:"learning_rate(step=None)"}),"\n",(0,n.jsx)(t.p,{children:"Returns the current learning rate."}),"\n",(0,n.jsx)(t.h4,{id:"step",children:"step()"}),"\n",(0,n.jsx)(t.p,{children:"Update the model parameters based on current gradients."}),"\n",(0,n.jsx)(t.p,{children:"Optionally, will employ gradient modification or update learning\nrate."}),"\n",(0,n.jsxs)(t.h4,{id:"property-training_step",children:[(0,n.jsx)(t.em,{children:"property"})," training_step"]}),"\n",(0,n.jsx)(t.p,{children:"The current training step."}),"\n",(0,n.jsx)(t.h4,{id:"zero_gradset_to_nonetrue",children:"zero_grad(set_to_none=True)"}),"\n",(0,n.jsx)(t.p,{children:"Zero the gradients of optimized parameters."}),"\n",(0,n.jsxs)(t.h3,{id:"class-eoleutilsadafactorparams-lrnone-beta109-beta20999-eps11e-30-eps20001-cliping_threshold1-non_constant_decaytrue-enable_factorizationtrue-ams_gradtrue-weight_decay0",children:[(0,n.jsx)(t.em,{children:"class"})," eole.utils.AdaFactor(params, lr=None, beta1=0.9, beta2=0.999, eps1=1e-30, eps2=0.001, cliping_threshold=1, non_constant_decay=True, enable_factorization=True, ams_grad=True, weight_decay=0)"]}),"\n",(0,n.jsxs)(t.p,{children:["Bases: ",(0,n.jsx)(t.code,{children:"Optimizer"})]}),"\n",(0,n.jsx)(t.h4,{id:"stepclosurenone",children:"step(closure=None)"}),"\n",(0,n.jsx)(t.p,{children:"Perform a single optimization step to update parameter."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Parameters:"}),"\n",(0,n.jsx)(t.strong,{children:"closure"})," (",(0,n.jsx)(t.em,{children:"Callable"}),") \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers."]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,t,s)=>{s.d(t,{R:()=>a,x:()=>l});var n=s(6540);const r={},i=n.createContext(r);function a(e){const t=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);