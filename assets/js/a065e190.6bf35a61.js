"use strict";(self.webpackChunkdocusaurus_tsx=self.webpackChunkdocusaurus_tsx||[]).push([[5922],{3049:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>d,toc:()=>o});var l=i(4848),t=i(8453);const r={},s="Training",d={id:"reference/Config/training",title:"Training",description:"pydantic model eole.config.training.OptimizerConfig[source]",source:"@site/docs/reference/Config/training.md",sourceDirName:"reference/Config",slug:"/reference/Config/training",permalink:"/eole/docs/reference/Config/training",draft:!1,unlisted:!1,editUrl:"https://github.com/eole-nlp/eole/tree/main/docs/docs/reference/Config/training.md",tags:[],version:"current",frontMatter:{},sidebar:"apiSidebar",previous:{title:"Main Entrypoints",permalink:"/eole/docs/reference/Config/run"},next:{title:"Transforms",permalink:"/eole/docs/reference/Config/transforms"}},a={},o=[{value:"<em>pydantic model</em> eole.config.training.OptimizerConfig[source]",id:"pydantic-model-eoleconfigtrainingoptimizerconfigsource",level:3},{value:"<em>field</em> adagrad_accumulator_init <em>: float</em> <em>= 0</em>",id:"field-adagrad_accumulator_init--float--0",level:4},{value:"<em>field</em> adam_beta1 <em>: float</em> <em>= 0.9</em>",id:"field-adam_beta1--float--09",level:4},{value:"<em>field</em> adam_beta2 <em>: float</em> <em>= 0.999</em>",id:"field-adam_beta2--float--0999",level:4},{value:"<em>field</em> decay_method <em>: Literal[&#39;noam&#39;, &#39;noamwd&#39;, &#39;cosine&#39;, &#39;rsqrt&#39;, &#39;none&#39;]</em> <em>= &#39;none&#39;</em>",id:"field-decay_method--literalnoam-noamwd-cosine-rsqrt-none--none",level:4},{value:"<em>field</em> decay_steps <em>: int</em> <em>= 10000</em>",id:"field-decay_steps--int--10000",level:4},{value:"<em>field</em> learning_rate <em>: float</em> <em>= 1.0</em>",id:"field-learning_rate--float--10",level:4},{value:"<em>field</em> learning_rate_decay <em>: float</em> <em>= 0.5</em>",id:"field-learning_rate_decay--float--05",level:4},{value:"<em>field</em> optim <em>: Literal[&#39;sgd&#39;, &#39;adagrad&#39;, &#39;adadelta&#39;, &#39;adam&#39;, &#39;adamw&#39;, &#39;sparseadam&#39;, &#39;adafactor&#39;, &#39;fusedadam&#39;, &#39;adamw8bit&#39;, &#39;pagedadamw8bit&#39;, &#39;pagedadamw32bit&#39;]</em> <em>= &#39;sgd&#39;</em>",id:"field-optim--literalsgd-adagrad-adadelta-adam-adamw-sparseadam-adafactor-fusedadam-adamw8bit-pagedadamw8bit-pagedadamw32bit--sgd",level:4},{value:"<em>field</em> reset_optim <em>: Literal[&#39;none&#39;, &#39;all&#39;, &#39;states&#39;, &#39;keep_states&#39;]</em> <em>= &#39;none&#39;</em>",id:"field-reset_optim--literalnone-all-states-keep_states--none",level:4},{value:"<em>field</em> start_decay_steps <em>: int</em> <em>= 50000</em>",id:"field-start_decay_steps--int--50000",level:4},{value:"<em>field</em> warmup_steps <em>: int</em> <em>= 4000</em>",id:"field-warmup_steps--int--4000",level:4},{value:"<em>field</em> weight_decay <em>: float</em> <em>= 0.0</em>",id:"field-weight_decay--float--00",level:4},{value:"<em>pydantic model</em> eole.config.training.TrainingConfig[source]",id:"pydantic-model-eoleconfigtrainingtrainingconfigsource",level:3},{value:"<em>field</em> accum_count <em>: List[int]</em> <em>= [1]</em>",id:"field-accum_count--listint--1",level:4},{value:"<em>field</em> accum_steps <em>: List[int]</em> <em>= [0]</em>",id:"field-accum_steps--listint--0",level:4},{value:"<em>field</em> apex_opt_level <em>: Literal[&#39;&#39;, &#39;O0&#39;, &#39;O1&#39;, &#39;O2&#39;, &#39;O3&#39;]</em> <em>= &#39;&#39;</em>",id:"field-apex_opt_level--literal-o0-o1-o2-o3--",level:4},{value:"<em>field</em> attention_dropout <em>: List[float]</em> <em>= [0.1]</em>",id:"field-attention_dropout--listfloat--01",level:4},{value:"<em>field</em> average_decay <em>: float</em> <em>= 0.0</em>",id:"field-average_decay--float--00",level:4},{value:"<em>field</em> average_every <em>: int</em> <em>= 1</em>",id:"field-average_every--int--1",level:4},{value:"<em>field</em> batch_size <em>: int</em> <em>= 64</em>",id:"field-batch_size--int--64",level:4},{value:"<em>field</em> batch_size_multiple <em>: int</em> <em>= 1</em>",id:"field-batch_size_multiple--int--1",level:4},{value:"<em>field</em> batch_type <em>: Literal[&#39;sents&#39;, &#39;tokens&#39;]</em> <em>= &#39;sents&#39;</em>",id:"field-batch_type--literalsents-tokens--sents",level:4},{value:"<em>field</em> bucket_size <em>: int</em> <em>= 262144</em>",id:"field-bucket_size--int--262144",level:4},{value:"<em>field</em> bucket_size_increment <em>: int</em> <em>= 0</em>",id:"field-bucket_size_increment--int--0",level:4},{value:"<em>field</em> bucket_size_init <em>: int</em> <em>= -1</em>",id:"field-bucket_size_init--int---1",level:4},{value:"<em>field</em> data_type <em>: str | None</em> <em>= &#39;text&#39;</em>",id:"field-data_type--str--none--text",level:4},{value:"<em>field</em> dropout <em>: List[float]</em> <em>= [0.3]</em>",id:"field-dropout--listfloat--03",level:4},{value:"<em>field</em> dropout_steps <em>: List[int]</em> <em>= [0]</em>",id:"field-dropout_steps--listint--0",level:4},{value:"<em>field</em> dummy_load <em>: bool | None</em> <em>= False</em>",id:"field-dummy_load--bool--none--false",level:4},{value:"<em>field</em> early_stopping <em>: int</em> <em>= 0</em>",id:"field-early_stopping--int--0",level:4},{value:"<em>field</em> early_stopping_criteria <em>: str | None</em> <em>= None</em>",id:"field-early_stopping_criteria--str--none--none",level:4},{value:"<em>field</em> estim_loss_lambda <em>: List[float]</em> <em>= [1.0]</em>",id:"field-estim_loss_lambda--listfloat--10",level:4},{value:"<em>field</em> estim_loss_lambda_steps <em>: List[int]</em> <em>= [0]</em>",id:"field-estim_loss_lambda_steps--listint--0",level:4},{value:"<em>field</em> freeze_decoder <em>: bool</em> <em>= False</em>",id:"field-freeze_decoder--bool--false",level:4},{value:"<em>field</em> freeze_encoder <em>: bool</em> <em>= False</em>",id:"field-freeze_encoder--bool--false",level:4},{value:"<em>field</em> keep_checkpoint <em>: int</em> <em>= -1</em>",id:"field-keep_checkpoint--int---1",level:4},{value:"<em>field</em> label_smoothing <em>: float</em> <em>= 0.0</em>",id:"field-label_smoothing--float--00",level:4},{value:"<em>field</em> lm_prior_lambda <em>: float</em> <em>= 0.0</em>",id:"field-lm_prior_lambda--float--00",level:4},{value:"<em>field</em> lm_prior_model <em>: str | None</em> <em>= None</em>",id:"field-lm_prior_model--str--none--none",level:4},{value:"<em>field</em> lm_prior_tau <em>: float</em> <em>= 1.0</em>",id:"field-lm_prior_tau--float--10",level:4},{value:"<em>field</em> loss_scale <em>: float</em> <em>= 0.0</em>",id:"field-loss_scale--float--00",level:4},{value:"<em>field</em> max_grad_norm <em>: float</em> <em>= 5</em>",id:"field-max_grad_norm--float--5",level:4},{value:"<em>field</em> normalization <em>: Literal[&#39;sents&#39;, &#39;tokens&#39;]</em> <em>= &#39;sents&#39;</em>",id:"field-normalization--literalsents-tokens--sents",level:4},{value:"<em>field</em> num_workers <em>: int</em> <em>= 2</em>",id:"field-num_workers--int--2",level:4},{value:"<em>field</em> param_init <em>: float</em> <em>= 0.1</em>",id:"field-param_init--float--01",level:4},{value:"<em>field</em> param_init_method <em>: Literal[&#39;xavier_uniform&#39;, &#39;uniform&#39;, &#39;normal&#39;]</em> <em>= &#39;uniform&#39;</em>",id:"field-param_init_method--literalxavier_uniform-uniform-normal--uniform",level:4},{value:"<em>field</em> pre_word_vecs_dec <em>: str | None</em> <em>= None</em>",id:"field-pre_word_vecs_dec--str--none--none",level:4},{value:"<em>field</em> pre_word_vecs_enc <em>: str | None</em> <em>= None</em>",id:"field-pre_word_vecs_enc--str--none--none",level:4},{value:"<em>field</em> prefetch_factor <em>: int</em> <em>= 200</em>",id:"field-prefetch_factor--int--200",level:4},{value:"<em>field</em> save_checkpoint_steps <em>: int</em> <em>= 5000</em>",id:"field-save_checkpoint_steps--int--5000",level:4},{value:"<em>field</em> save_format <em>: Literal[&#39;pytorch&#39;, &#39;safetensors&#39;]</em> <em>= &#39;pytorch&#39;</em>",id:"field-save_format--literalpytorch-safetensors--pytorch",level:4},{value:"<em>field</em> score_threshold <em>: float</em> <em>= 0.68</em>",id:"field-score_threshold--float--068",level:4},{value:"<em>field</em> single_pass <em>: bool</em> <em>= False</em>",id:"field-single_pass--bool--false",level:4},{value:"<em>field</em> train_from <em>: str | None</em> <em>= None</em>",id:"field-train_from--str--none--none",level:4},{value:"<em>field</em> train_steps <em>: int</em> <em>= 100000</em>",id:"field-train_steps--int--100000",level:4},{value:"<em>field</em> truncated_decoder <em>: int</em> <em>= 0</em>",id:"field-truncated_decoder--int--0",level:4},{value:"<em>field</em> update_vocab <em>: bool</em> <em>= False</em>",id:"field-update_vocab--bool--false",level:4},{value:"<em>field</em> use_ckpting <em>: List[str]</em> <em>= []</em>",id:"field-use_ckpting--liststr--",level:4},{value:"<em>field</em> valid_batch_size <em>: int</em> <em>= 32</em>",id:"field-valid_batch_size--int--32",level:4},{value:"<em>field</em> valid_steps <em>: int</em> <em>= 10000</em>",id:"field-valid_steps--int--10000",level:4},{value:"<em>field</em> zero_out_prompt_loss <em>: bool</em> <em>= False</em>",id:"field-zero_out_prompt_loss--bool--false",level:4},{value:"<em>validator</em> checkpointing_layers  <em>\xbb</em>  <em>use_ckpting</em>[source]",id:"validator-checkpointing_layers----use_ckptingsource",level:4},{value:"get_model_path()[source]",id:"get_model_pathsource",level:4},{value:"<em>property</em> storage_dtype <em>: dtype</em>[source]",id:"property-storage_dtype--dtypesource",level:4}];function c(e){const n={a:"a",code:"code",details:"details",em:"em",h1:"h1",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",summary:"summary",ul:"ul",...(0,t.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.h1,{id:"training",children:"Training"}),"\n",(0,l.jsxs)(n.h3,{id:"pydantic-model-eoleconfigtrainingoptimizerconfigsource",children:[(0,l.jsx)(n.em,{children:"pydantic model"})," eole.config.training.OptimizerConfig",(0,l.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/config/training.py#L11-L87",children:"[source]"})]}),"\n",(0,l.jsxs)(n.p,{children:["Bases: ",(0,l.jsx)(n.code,{children:"Config"})]}),"\n",(0,l.jsx)(n.p,{children:"Everything related to optimizers.\nMight be split into multiple subclasses later.\nNote: not fully sufficient (yet) to replace full opt namespace in build_torch_optimizer.\nSome other parameters (hidden_size, compute_dtype, apex_opt_level, etc.) are accessed."}),"\n",(0,l.jsx)(n.p,{}),(0,l.jsxs)(n.details,{className:"autodoc_pydantic_collapsable_json",children:["\n",(0,l.jsx)(n.summary,{children:"Show JSON schema"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-json",children:'{\n   "title": "OptimizerConfig",\n   "description": "Everything related to optimizers.\\nMight be split into multiple subclasses later.\\nNote: not fully sufficient (yet) to replace full opt namespace in build_torch_optimizer.\\nSome other parameters (hidden_size, compute_dtype, apex_opt_level, etc.) are accessed.",\n   "type": "object",\n   "properties": {\n      "optim": {\n         "default": "sgd",\n         "description": "Optimization method.",\n         "enum": [\n            "sgd",\n            "adagrad",\n            "adadelta",\n            "adam",\n            "adamw",\n            "sparseadam",\n            "adafactor",\n            "fusedadam",\n            "adamw8bit",\n            "pagedadamw8bit",\n            "pagedadamw32bit"\n         ],\n         "title": "Optim",\n         "type": "string"\n      },\n      "adagrad_accumulator_init": {\n         "default": 0,\n         "description": "Initialize the accumulator values in adagrad. Mirrors initial_accumulator_value flag from tensorflow adagrad implementation (default 0.1 there).",\n         "title": "Adagrad Accumulator Init",\n         "type": "number"\n      },\n      "adam_beta1": {\n         "default": 0.9,\n         "description": "Beta1 parameter used by Adam. Almost without exception a value of 0.9 is used in the literature, seemingly giving good results, so we would discourage changing this value from the default without due consideration.",\n         "title": "Adam Beta1",\n         "type": "number"\n      },\n      "adam_beta2": {\n         "default": 0.999,\n         "description": "Beta2 parameter used by Adam. Typically a value of 0.999 is recommended, as this is the value suggested by the original paper describing Adam, and is also the value adopted in other frameworks such as Tensorflow (https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) and Keras (https://keras.io/optimizers/). Whereas recently the paper Attention is All You Need suggested a value of 0.98 for beta2, this parameter may not work well for normal models / default baselines.",\n         "title": "Adam Beta2",\n         "type": "number"\n      },\n      "weight_decay": {\n         "default": 0.0,\n         "description": "Weight decay to forward to torch Optimizer.",\n         "title": "Weight Decay",\n         "type": "number"\n      },\n      "learning_rate": {\n         "default": 1.0,\n         "description": "Starting learning rate. Recommended settings: sgd=1, adagrad=0.1, adadelta=1, adam=0.001.",\n         "title": "Learning Rate",\n         "type": "number"\n      },\n      "learning_rate_decay": {\n         "default": 0.5,\n         "description": "Decay learning rate by this much if steps have gone past start_decay_steps.",\n         "title": "Learning Rate Decay",\n         "type": "number"\n      },\n      "start_decay_steps": {\n         "default": 50000,\n         "description": "Start decaying every decay_steps after this many steps.",\n         "title": "Start Decay Steps",\n         "type": "integer"\n      },\n      "decay_steps": {\n         "default": 10000,\n         "description": "Frequency for learning rate decay, in steps.",\n         "title": "Decay Steps",\n         "type": "integer"\n      },\n      "decay_method": {\n         "default": "none",\n         "description": "Custom decay method to use.",\n         "enum": [\n            "noam",\n            "noamwd",\n            "cosine",\n            "rsqrt",\n            "none"\n         ],\n         "title": "Decay Method",\n         "type": "string"\n      },\n      "warmup_steps": {\n         "default": 4000,\n         "description": "Number of warmup steps for custom decay.",\n         "title": "Warmup Steps",\n         "type": "integer"\n      },\n      "reset_optim": {\n         "default": "none",\n         "description": "Optimization resetter when using train_from.",\n         "enum": [\n            "none",\n            "all",\n            "states",\n            "keep_states"\n         ],\n         "title": "Reset Optim",\n         "type": "string"\n      }\n   },\n   "additionalProperties": false\n}\n'})}),"\n"]}),(0,l.jsx)(n.p,{}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Config:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"validate_assignment"}),": ",(0,l.jsx)(n.em,{children:"bool = True"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"validate_default"}),": ",(0,l.jsx)(n.em,{children:"bool = True"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"use_enum_values"}),": ",(0,l.jsx)(n.em,{children:"bool = True"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"extra"}),": ",(0,l.jsx)(n.em,{children:"str = forbid"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"protected_namespaces"}),": ",(0,l.jsx)(n.em,{children:"tuple = ()"})]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Fields:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.adagrad_accumulator_init",children:(0,l.jsx)(n.code,{children:"adagrad_accumulator_init (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.adam_beta1",children:(0,l.jsx)(n.code,{children:"adam_beta1 (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.adam_beta2",children:(0,l.jsx)(n.code,{children:"adam_beta2 (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.decay_method",children:(0,l.jsx)(n.code,{children:"decay_method (Literal['noam', 'noamwd', 'cosine', 'rsqrt', 'none'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.decay_steps",children:(0,l.jsx)(n.code,{children:"decay_steps (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.learning_rate",children:(0,l.jsx)(n.code,{children:"learning_rate (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.learning_rate_decay",children:(0,l.jsx)(n.code,{children:"learning_rate_decay (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.optim",children:(0,l.jsx)(n.code,{children:"optim (Literal['sgd', 'adagrad', 'adadelta', 'adam', 'adamw', 'sparseadam', 'adafactor', 'fusedadam', 'adamw8bit', 'pagedadamw8bit', 'pagedadamw32bit'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.reset_optim",children:(0,l.jsx)(n.code,{children:"reset_optim (Literal['none', 'all', 'states', 'keep_states'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.start_decay_steps",children:(0,l.jsx)(n.code,{children:"start_decay_steps (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.warmup_steps",children:(0,l.jsx)(n.code,{children:"warmup_steps (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig.weight_decay",children:(0,l.jsx)(n.code,{children:"weight_decay (float)"})})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-adagrad_accumulator_init--float--0",children:[(0,l.jsx)(n.em,{children:"field"})," adagrad_accumulator_init ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0"})]}),"\n",(0,l.jsx)(n.p,{children:"Initialize the accumulator values in adagrad. Mirrors initial_accumulator_value flag from tensorflow adagrad implementation (default 0.1 there)."}),"\n",(0,l.jsxs)(n.h4,{id:"field-adam_beta1--float--09",children:[(0,l.jsx)(n.em,{children:"field"})," adam_beta1 ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.9"})]}),"\n",(0,l.jsx)(n.p,{children:"Beta1 parameter used by Adam. Almost without exception a value of 0.9 is used in the literature, seemingly giving good results, so we would discourage changing this value from the default without due consideration."}),"\n",(0,l.jsxs)(n.h4,{id:"field-adam_beta2--float--0999",children:[(0,l.jsx)(n.em,{children:"field"})," adam_beta2 ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.999"})]}),"\n",(0,l.jsxs)(n.p,{children:["Beta2 parameter used by Adam. Typically a value of 0.999 is recommended, as this is the value suggested by the original paper describing Adam, and is also the value adopted in other frameworks such as Tensorflow (",(0,l.jsx)(n.a,{href:"https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer",children:"https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer"}),") and Keras (",(0,l.jsx)(n.a,{href:"https://keras.io/optimizers/",children:"https://keras.io/optimizers/"}),"). Whereas recently the paper Attention is All You Need suggested a value of 0.98 for beta2, this parameter may not work well for normal models / default baselines."]}),"\n",(0,l.jsxs)(n.h4,{id:"field-decay_method--literalnoam-noamwd-cosine-rsqrt-none--none",children:[(0,l.jsx)(n.em,{children:"field"})," decay_method ",(0,l.jsx)(n.em,{children:": Literal['noam', 'noamwd', 'cosine', 'rsqrt', 'none']"})," ",(0,l.jsx)(n.em,{children:"= 'none'"})]}),"\n",(0,l.jsx)(n.p,{children:"Custom decay method to use."}),"\n",(0,l.jsxs)(n.h4,{id:"field-decay_steps--int--10000",children:[(0,l.jsx)(n.em,{children:"field"})," decay_steps ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 10000"})]}),"\n",(0,l.jsx)(n.p,{children:"Frequency for learning rate decay, in steps."}),"\n",(0,l.jsxs)(n.h4,{id:"field-learning_rate--float--10",children:[(0,l.jsx)(n.em,{children:"field"})," learning_rate ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 1.0"})]}),"\n",(0,l.jsx)(n.p,{children:"Starting learning rate. Recommended settings: sgd=1, adagrad=0.1, adadelta=1, adam=0.001."}),"\n",(0,l.jsxs)(n.h4,{id:"field-learning_rate_decay--float--05",children:[(0,l.jsx)(n.em,{children:"field"})," learning_rate_decay ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.5"})]}),"\n",(0,l.jsx)(n.p,{children:"Decay learning rate by this much if steps have gone past start_decay_steps."}),"\n",(0,l.jsxs)(n.h4,{id:"field-optim--literalsgd-adagrad-adadelta-adam-adamw-sparseadam-adafactor-fusedadam-adamw8bit-pagedadamw8bit-pagedadamw32bit--sgd",children:[(0,l.jsx)(n.em,{children:"field"})," optim ",(0,l.jsx)(n.em,{children:": Literal['sgd', 'adagrad', 'adadelta', 'adam', 'adamw', 'sparseadam', 'adafactor', 'fusedadam', 'adamw8bit', 'pagedadamw8bit', 'pagedadamw32bit']"})," ",(0,l.jsx)(n.em,{children:"= 'sgd'"})]}),"\n",(0,l.jsx)(n.p,{children:"Optimization method."}),"\n",(0,l.jsxs)(n.h4,{id:"field-reset_optim--literalnone-all-states-keep_states--none",children:[(0,l.jsx)(n.em,{children:"field"})," reset_optim ",(0,l.jsx)(n.em,{children:": Literal['none', 'all', 'states', 'keep_states']"})," ",(0,l.jsx)(n.em,{children:"= 'none'"})]}),"\n",(0,l.jsx)(n.p,{children:"Optimization resetter when using train_from."}),"\n",(0,l.jsxs)(n.h4,{id:"field-start_decay_steps--int--50000",children:[(0,l.jsx)(n.em,{children:"field"})," start_decay_steps ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 50000"})]}),"\n",(0,l.jsx)(n.p,{children:"Start decaying every decay_steps after this many steps."}),"\n",(0,l.jsxs)(n.h4,{id:"field-warmup_steps--int--4000",children:[(0,l.jsx)(n.em,{children:"field"})," warmup_steps ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 4000"})]}),"\n",(0,l.jsx)(n.p,{children:"Number of warmup steps for custom decay."}),"\n",(0,l.jsxs)(n.h4,{id:"field-weight_decay--float--00",children:[(0,l.jsx)(n.em,{children:"field"})," weight_decay ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.0"})]}),"\n",(0,l.jsx)(n.p,{children:"Weight decay to forward to torch Optimizer."}),"\n",(0,l.jsxs)(n.h3,{id:"pydantic-model-eoleconfigtrainingtrainingconfigsource",children:[(0,l.jsx)(n.em,{children:"pydantic model"})," eole.config.training.TrainingConfig",(0,l.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/config/training.py#L90-L384",children:"[source]"})]}),"\n",(0,l.jsxs)(n.p,{children:["Bases: ",(0,l.jsx)(n.code,{children:"RunningConfig"}),", ",(0,l.jsx)(n.a,{href:"#eole.config.training.OptimizerConfig",children:(0,l.jsx)(n.code,{children:"OptimizerConfig"})}),", ",(0,l.jsx)(n.a,{href:"/eole/docs/reference/Config/run#eole.config.common.LoRaConfig",children:(0,l.jsx)(n.code,{children:"LoRaConfig"})}),", ",(0,l.jsx)(n.a,{href:"/eole/docs/reference/Config/run#eole.config.common.QuantizeConfig",children:(0,l.jsx)(n.code,{children:"QuantizeConfig"})})]}),"\n",(0,l.jsx)(n.p,{}),(0,l.jsxs)(n.details,{className:"autodoc_pydantic_collapsable_json",children:["\n",(0,l.jsx)(n.summary,{children:"Show JSON schema"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-json",children:'{\n   "title": "TrainingConfig",\n   "type": "object",\n   "properties": {\n      "quant_layers": {\n         "default": [],\n         "description": "List of layers to be compressed in 4/8bit.",\n         "items": {\n            "type": "string"\n         },\n         "title": "Quant Layers",\n         "type": "array"\n      },\n      "quant_type": {\n         "default": "",\n         "description": "Type of compression.",\n         "enum": [\n            "",\n            "bnb_8bit",\n            "bnb_FP4",\n            "bnb_NF4",\n            "awq_gemm",\n            "awq_gemv"\n         ],\n         "title": "Quant Type",\n         "type": "string"\n      },\n      "w_bit": {\n         "default": 4,\n         "description": "W_bit quantization",\n         "title": "W Bit",\n         "type": "integer"\n      },\n      "group_size": {\n         "default": 128,\n         "description": "Group size quantization.",\n         "title": "Group Size",\n         "type": "integer"\n      },\n      "lora_layers": {\n         "default": [],\n         "description": "List of layers to be replaced by LoRa layers. E.g. [\'linear_values\', \'linear_query\'] (\\u00a74.2 in https://arxiv.org/abs/2106.09685)",\n         "items": {\n            "type": "string"\n         },\n         "title": "Lora Layers",\n         "type": "array"\n      },\n      "lora_embedding": {\n         "default": false,\n         "description": "Replace embeddings with LoRa Embeddings (\\u00a75.1)",\n         "title": "Lora Embedding",\n         "type": "boolean"\n      },\n      "lora_rank": {\n         "default": 2,\n         "description": "r=2 successfully tested with NLLB-200 3.3B",\n         "title": "Lora Rank",\n         "type": "integer"\n      },\n      "lora_alpha": {\n         "default": 1,\n         "description": "\\u00a74.1 https://arxiv.org/abs/2106.09685",\n         "title": "Lora Alpha",\n         "type": "integer"\n      },\n      "lora_dropout": {\n         "default": 0.0,\n         "description": "Rule of thumb: same value as in main model.",\n         "title": "Lora Dropout",\n         "type": "number"\n      },\n      "optim": {\n         "default": "sgd",\n         "description": "Optimization method.",\n         "enum": [\n            "sgd",\n            "adagrad",\n            "adadelta",\n            "adam",\n            "adamw",\n            "sparseadam",\n            "adafactor",\n            "fusedadam",\n            "adamw8bit",\n            "pagedadamw8bit",\n            "pagedadamw32bit"\n         ],\n         "title": "Optim",\n         "type": "string"\n      },\n      "adagrad_accumulator_init": {\n         "default": 0,\n         "description": "Initialize the accumulator values in adagrad. Mirrors initial_accumulator_value flag from tensorflow adagrad implementation (default 0.1 there).",\n         "title": "Adagrad Accumulator Init",\n         "type": "number"\n      },\n      "adam_beta1": {\n         "default": 0.9,\n         "description": "Beta1 parameter used by Adam. Almost without exception a value of 0.9 is used in the literature, seemingly giving good results, so we would discourage changing this value from the default without due consideration.",\n         "title": "Adam Beta1",\n         "type": "number"\n      },\n      "adam_beta2": {\n         "default": 0.999,\n         "description": "Beta2 parameter used by Adam. Typically a value of 0.999 is recommended, as this is the value suggested by the original paper describing Adam, and is also the value adopted in other frameworks such as Tensorflow (https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) and Keras (https://keras.io/optimizers/). Whereas recently the paper Attention is All You Need suggested a value of 0.98 for beta2, this parameter may not work well for normal models / default baselines.",\n         "title": "Adam Beta2",\n         "type": "number"\n      },\n      "weight_decay": {\n         "default": 0.0,\n         "description": "Weight decay to forward to torch Optimizer.",\n         "title": "Weight Decay",\n         "type": "number"\n      },\n      "learning_rate": {\n         "default": 1.0,\n         "description": "Starting learning rate. Recommended settings: sgd=1, adagrad=0.1, adadelta=1, adam=0.001.",\n         "title": "Learning Rate",\n         "type": "number"\n      },\n      "learning_rate_decay": {\n         "default": 0.5,\n         "description": "Decay learning rate by this much if steps have gone past start_decay_steps.",\n         "title": "Learning Rate Decay",\n         "type": "number"\n      },\n      "start_decay_steps": {\n         "default": 50000,\n         "description": "Start decaying every decay_steps after this many steps.",\n         "title": "Start Decay Steps",\n         "type": "integer"\n      },\n      "decay_steps": {\n         "default": 10000,\n         "description": "Frequency for learning rate decay, in steps.",\n         "title": "Decay Steps",\n         "type": "integer"\n      },\n      "decay_method": {\n         "default": "none",\n         "description": "Custom decay method to use.",\n         "enum": [\n            "noam",\n            "noamwd",\n            "cosine",\n            "rsqrt",\n            "none"\n         ],\n         "title": "Decay Method",\n         "type": "string"\n      },\n      "warmup_steps": {\n         "default": 4000,\n         "description": "Number of warmup steps for custom decay.",\n         "title": "Warmup Steps",\n         "type": "integer"\n      },\n      "reset_optim": {\n         "default": "none",\n         "description": "Optimization resetter when using train_from.",\n         "enum": [\n            "none",\n            "all",\n            "states",\n            "keep_states"\n         ],\n         "title": "Reset Optim",\n         "type": "string"\n      },\n      "gpu_ranks": {\n         "default": [],\n         "description": "List of ranks for each process.",\n         "items": {\n            "type": "integer"\n         },\n         "title": "Gpu Ranks",\n         "type": "array"\n      },\n      "world_size": {\n         "default": 1,\n         "description": "Total number of distributed processes.",\n         "title": "World Size",\n         "type": "integer"\n      },\n      "parallel_mode": {\n         "default": "data_parallel",\n         "description": "Distributed mode.",\n         "enum": [\n            "data_parallel",\n            "tensor_parallel"\n         ],\n         "title": "Parallel Mode",\n         "type": "string"\n      },\n      "gpu_backend": {\n         "default": "nccl",\n         "description": "Type of torch distributed backend.",\n         "title": "Gpu Backend",\n         "type": "string"\n      },\n      "gpu_verbose_level": {\n         "default": 0,\n         "description": "Gives more info on each process per GPU.",\n         "title": "Gpu Verbose Level",\n         "type": "integer"\n      },\n      "master_ip": {\n         "default": "localhost",\n         "description": "IP of master for torch.distributed training.",\n         "title": "Master Ip",\n         "type": "string"\n      },\n      "master_port": {\n         "default": 10000,\n         "description": "Port of master for torch.distributed training.",\n         "title": "Master Port",\n         "type": "integer"\n      },\n      "timeout": {\n         "default": 60,\n         "description": "Timeout for one GPU to wait for the others.",\n         "title": "Timeout",\n         "type": "integer"\n      },\n      "model_path": {\n         "default": "model",\n         "description": "Path to directory containing all model components.",\n         "title": "Model Path",\n         "type": "string"\n      },\n      "self_attn_backend": {\n         "default": "flash",\n         "description": "Self-attention backend.",\n         "enum": [\n            "flash",\n            "pytorch"\n         ],\n         "title": "Self Attn Backend",\n         "type": "string"\n      },\n      "compute_dtype": {\n         "description": "Compute dtype (precision) to use for main compute. Some parameters might have other dtypes for specific cases (e.g. torch.amp -- See eole.config.training.TrainingConfig.storage_dtype) fp32 to force slow fp16 model on gtx1080, int8 to enable pytorch native 8-bit quantization (cpu only).",\n         "enum": [\n            "fp32",\n            "fp16",\n            "int8",\n            "bf16"\n         ],\n         "title": "Compute Dtype",\n         "type": "string"\n      },\n      "torch_compile": {\n         "default": false,\n         "description": "Use torch.compile with dynamic=True.",\n         "title": "Torch Compile",\n         "type": "boolean"\n      },\n      "param_init": {\n         "default": 0.1,\n         "description": "Support value for uniform distribution parameters initialization. Set to 0 not to use initialization.",\n         "title": "Param Init",\n         "type": "number"\n      },\n      "param_init_method": {\n         "default": "uniform",\n         "description": "Parameter initialization method.",\n         "enum": [\n            "xavier_uniform",\n            "uniform",\n            "normal"\n         ],\n         "title": "Param Init Method",\n         "type": "string"\n      },\n      "freeze_encoder": {\n         "default": false,\n         "description": "Freeze parameters in encoder.",\n         "title": "Freeze Encoder",\n         "type": "boolean"\n      },\n      "freeze_decoder": {\n         "default": false,\n         "description": "Freeze parameters in decoder.",\n         "title": "Freeze Decoder",\n         "type": "boolean"\n      },\n      "pre_word_vecs_enc": {\n         "anyOf": [\n            {\n               "type": "string"\n            },\n            {\n               "type": "null"\n            }\n         ],\n         "default": null,\n         "description": "If a valid path is specified, will load pretrained word embeddings on the encoder side.",\n         "title": "Pre Word Vecs Enc"\n      },\n      "pre_word_vecs_dec": {\n         "anyOf": [\n            {\n               "type": "string"\n            },\n            {\n               "type": "null"\n            }\n         ],\n         "default": null,\n         "description": "If a valid path is specified, will load pretrained word embeddings on the decoder side.",\n         "title": "Pre Word Vecs Dec"\n      },\n      "data_type": {\n         "anyOf": [\n            {\n               "type": "string"\n            },\n            {\n               "type": "null"\n            }\n         ],\n         "default": "text",\n         "title": "Data Type"\n      },\n      "bucket_size": {\n         "default": 262144,\n         "description": "A bucket is a buffer of bucket_size examples to pick from the various corpora. The dynamic iterator batches batch_size items from the bucket and shuffle them.",\n         "title": "Bucket Size",\n         "type": "integer"\n      },\n      "bucket_size_init": {\n         "default": -1,\n         "description": "Bucket size is initialized with this amount of examples (see bucket_size_increment).",\n         "title": "Bucket Size Init",\n         "type": "integer"\n      },\n      "bucket_size_increment": {\n         "default": 0,\n         "description": "Bucket size incremented with this amount of examples at each new bucket (up to bucket_size).",\n         "title": "Bucket Size Increment",\n         "type": "integer"\n      },\n      "prefetch_factor": {\n         "default": 200,\n         "description": "Number of mini-batches loaded in advance to avoid the GPU waiting during processing of next bucket.",\n         "title": "Prefetch Factor",\n         "type": "integer"\n      },\n      "save_format": {\n         "default": "pytorch",\n         "description": "Format to save the model weights.",\n         "enum": [\n            "pytorch",\n            "safetensors"\n         ],\n         "title": "Save Format",\n         "type": "string"\n      },\n      "save_checkpoint_steps": {\n         "default": 5000,\n         "description": "Frequency of checkpoint saving (in steps).",\n         "title": "Save Checkpoint Steps",\n         "type": "integer"\n      },\n      "keep_checkpoint": {\n         "default": -1,\n         "description": "Number of checkpoints to retain. (-1 retains all)",\n         "title": "Keep Checkpoint",\n         "type": "integer"\n      },\n      "train_from": {\n         "anyOf": [\n            {\n               "type": "string"\n            },\n            {\n               "type": "null"\n            }\n         ],\n         "default": null,\n         "description": "Pretrained model/checkpoint weights to continue training from.",\n         "title": "Train From"\n      },\n      "num_workers": {\n         "default": 2,\n         "description": "Number of workers for pytorch.DataLoader objects.",\n         "title": "Num Workers",\n         "type": "integer"\n      },\n      "batch_size": {\n         "default": 64,\n         "description": "Maximum batch size for training.",\n         "title": "Batch Size",\n         "type": "integer"\n      },\n      "batch_size_multiple": {\n         "default": 1,\n         "description": "Batch size multiple for token batches.",\n         "title": "Batch Size Multiple",\n         "type": "integer"\n      },\n      "batch_type": {\n         "default": "sents",\n         "description": "Batch grouping for batch_size.",\n         "enum": [\n            "sents",\n            "tokens"\n         ],\n         "title": "Batch Type",\n         "type": "string"\n      },\n      "normalization": {\n         "default": "sents",\n         "description": "Normalization method of the gradient.",\n         "enum": [\n            "sents",\n            "tokens"\n         ],\n         "title": "Normalization",\n         "type": "string"\n      },\n      "accum_count": {\n         "default": [\n            1\n         ],\n         "description": "Accumulate gradient this many times. Approximately equivalent to updating batch_size * accum_count batches at once. Recommended for transformer.",\n         "items": {\n            "type": "integer"\n         },\n         "title": "Accum Count",\n         "type": "array"\n      },\n      "accum_steps": {\n         "default": [\n            0\n         ],\n         "description": "Steps at which accum_count values change.",\n         "items": {\n            "type": "integer"\n         },\n         "title": "Accum Steps",\n         "type": "array"\n      },\n      "valid_steps": {\n         "default": 10000,\n         "description": "Frequency of validation, in steps.",\n         "title": "Valid Steps",\n         "type": "integer"\n      },\n      "valid_batch_size": {\n         "default": 32,\n         "description": "Maximum batch size for validation.",\n         "title": "Valid Batch Size",\n         "type": "integer"\n      },\n      "train_steps": {\n         "default": 100000,\n         "description": "Number of training steps.",\n         "title": "Train Steps",\n         "type": "integer"\n      },\n      "single_pass": {\n         "default": false,\n         "description": "Make a single pass over the training dataset.",\n         "title": "Single Pass",\n         "type": "boolean"\n      },\n      "early_stopping": {\n         "default": 0,\n         "description": "Number of validation steps without improving that will trigger early stop of training.",\n         "title": "Early Stopping",\n         "type": "integer"\n      },\n      "early_stopping_criteria": {\n         "anyOf": [\n            {\n               "type": "string"\n            },\n            {\n               "type": "null"\n            }\n         ],\n         "default": null,\n         "description": "Criteria to use for early stopping.",\n         "title": "Early Stopping Criteria"\n      },\n      "max_grad_norm": {\n         "default": 5,\n         "description": "If the norm of the gradient vector exceeds this value, renormalize it to have the norm equal to max_grad_norm.",\n         "title": "Max Grad Norm",\n         "type": "number"\n      },\n      "dropout": {\n         "default": [\n            0.3\n         ],\n         "description": "Dropout probability.",\n         "items": {\n            "type": "number"\n         },\n         "title": "Dropout",\n         "type": "array"\n      },\n      "attention_dropout": {\n         "default": [\n            0.1\n         ],\n         "description": "Attention dropout probability.",\n         "items": {\n            "type": "number"\n         },\n         "title": "Attention Dropout",\n         "type": "array"\n      },\n      "dropout_steps": {\n         "default": [\n            0\n         ],\n         "description": "Steps at which dropout changes.",\n         "items": {\n            "type": "integer"\n         },\n         "title": "Dropout Steps",\n         "type": "array"\n      },\n      "truncated_decoder": {\n         "default": 0,\n         "description": "Truncated bptt.",\n         "title": "Truncated Decoder",\n         "type": "integer"\n      },\n      "label_smoothing": {\n         "default": 0.0,\n         "description": "Label smoothing value epsilon. Probability of all non-true labels will be smoothed by epsilon/(vocab_size-1). Set to 0 to turn off label smoothing. (https://arxiv.org/abs/1512.00567)",\n         "title": "Label Smoothing",\n         "type": "number"\n      },\n      "average_decay": {\n         "default": 0.0,\n         "description": "Exponential moving average decay (https://en.wikipedia.org/wiki/Moving_average). Set to other than 0 (e.g. 1e-4) to activate. Similar to Marian NMT implementation (http://www.aclweb.org/anthology/P18-4020).",\n         "title": "Average Decay",\n         "type": "number"\n      },\n      "average_every": {\n         "default": 1,\n         "description": "Step for moving average. Default is every update if average_decay is set.",\n         "title": "Average Every",\n         "type": "integer"\n      },\n      "loss_scale": {\n         "default": 0.0,\n         "description": "For FP16 training, the static loss scale to use. If not set, the loss scale is dynamically computed.",\n         "title": "Loss Scale",\n         "type": "number"\n      },\n      "apex_opt_level": {\n         "default": "",\n         "description": "For FP16 training, the opt_level to use. See https://nvidia.github.io/apex/amp.html#opt-levels.",\n         "enum": [\n            "",\n            "O0",\n            "O1",\n            "O2",\n            "O3"\n         ],\n         "title": "Apex Opt Level",\n         "type": "string"\n      },\n      "zero_out_prompt_loss": {\n         "default": false,\n         "description": "Set the prompt loss to zero. Mostly for LLM finetuning. Will be enabled only if the `insert_mask_before_placeholder` transform is applied.",\n         "title": "Zero Out Prompt Loss",\n         "type": "boolean"\n      },\n      "use_ckpting": {\n         "default": [],\n         "description": "Use gradient checkpointing for those modules.",\n         "items": {\n            "type": "string"\n         },\n         "title": "Use Ckpting",\n         "type": "array"\n      },\n      "update_vocab": {\n         "default": false,\n         "description": "Update source and target existing vocabularies.",\n         "title": "Update Vocab",\n         "type": "boolean"\n      },\n      "lm_prior_model": {\n         "anyOf": [\n            {\n               "type": "string"\n            },\n            {\n               "type": "null"\n            }\n         ],\n         "default": null,\n         "description": "LM model to use to train the TM.",\n         "title": "Lm Prior Model"\n      },\n      "lm_prior_lambda": {\n         "default": 0.0,\n         "description": "LM Prior Lambda",\n         "title": "Lm Prior Lambda",\n         "type": "number"\n      },\n      "lm_prior_tau": {\n         "default": 1.0,\n         "description": "LM Prior Tau",\n         "title": "Lm Prior Tau",\n         "type": "number"\n      },\n      "estim_loss_lambda": {\n         "default": [\n            1.0\n         ],\n         "description": "Weight applied to estimator loss",\n         "items": {\n            "type": "number"\n         },\n         "title": "Estim Loss Lambda",\n         "type": "array"\n      },\n      "estim_loss_lambda_steps": {\n         "default": [\n            0\n         ],\n         "description": "Steps at which estimator loss lambda changes",\n         "items": {\n            "type": "integer"\n         },\n         "title": "Estim Loss Lambda Steps",\n         "type": "array"\n      },\n      "score_threshold": {\n         "default": 0.68,\n         "description": "Threshold to filterout data",\n         "title": "Score Threshold",\n         "type": "number"\n      },\n      "dummy_load": {\n         "anyOf": [\n            {\n               "type": "boolean"\n            },\n            {\n               "type": "null"\n            }\n         ],\n         "default": false,\n         "description": "Ignore some warnings if we are only loading the configuration prior to other operations, e.g. in `train_from` context.",\n         "title": "Dummy Load"\n      }\n   },\n   "additionalProperties": false\n}\n'})}),"\n"]}),(0,l.jsx)(n.p,{}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Config:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"validate_assignment"}),": ",(0,l.jsx)(n.em,{children:"bool = True"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"validate_default"}),": ",(0,l.jsx)(n.em,{children:"bool = True"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"use_enum_values"}),": ",(0,l.jsx)(n.em,{children:"bool = True"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"extra"}),": ",(0,l.jsx)(n.em,{children:"str = forbid"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"protected_namespaces"}),": ",(0,l.jsx)(n.em,{children:"tuple = ()"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"arbitrary_types_allowed"}),": ",(0,l.jsx)(n.em,{children:"bool = True"})]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Fields:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.accum_count",children:(0,l.jsx)(n.code,{children:"accum_count (List[int])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.accum_steps",children:(0,l.jsx)(n.code,{children:"accum_steps (List[int])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.apex_opt_level",children:(0,l.jsx)(n.code,{children:"apex_opt_level (Literal['', 'O0', 'O1', 'O2', 'O3'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.attention_dropout",children:(0,l.jsx)(n.code,{children:"attention_dropout (List[float])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.average_decay",children:(0,l.jsx)(n.code,{children:"average_decay (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.average_every",children:(0,l.jsx)(n.code,{children:"average_every (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.batch_size",children:(0,l.jsx)(n.code,{children:"batch_size (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.batch_size_multiple",children:(0,l.jsx)(n.code,{children:"batch_size_multiple (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.batch_type",children:(0,l.jsx)(n.code,{children:"batch_type (Literal['sents', 'tokens'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.bucket_size",children:(0,l.jsx)(n.code,{children:"bucket_size (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.bucket_size_increment",children:(0,l.jsx)(n.code,{children:"bucket_size_increment (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.bucket_size_init",children:(0,l.jsx)(n.code,{children:"bucket_size_init (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.data_type",children:(0,l.jsx)(n.code,{children:"data_type (str | None)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.dropout",children:(0,l.jsx)(n.code,{children:"dropout (List[float])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.dropout_steps",children:(0,l.jsx)(n.code,{children:"dropout_steps (List[int])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.dummy_load",children:(0,l.jsx)(n.code,{children:"dummy_load (bool | None)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.early_stopping",children:(0,l.jsx)(n.code,{children:"early_stopping (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.early_stopping_criteria",children:(0,l.jsx)(n.code,{children:"early_stopping_criteria (str | None)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.estim_loss_lambda",children:(0,l.jsx)(n.code,{children:"estim_loss_lambda (List[float])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.estim_loss_lambda_steps",children:(0,l.jsx)(n.code,{children:"estim_loss_lambda_steps (List[int])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.freeze_decoder",children:(0,l.jsx)(n.code,{children:"freeze_decoder (bool)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.freeze_encoder",children:(0,l.jsx)(n.code,{children:"freeze_encoder (bool)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.keep_checkpoint",children:(0,l.jsx)(n.code,{children:"keep_checkpoint (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.label_smoothing",children:(0,l.jsx)(n.code,{children:"label_smoothing (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.lm_prior_lambda",children:(0,l.jsx)(n.code,{children:"lm_prior_lambda (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.lm_prior_model",children:(0,l.jsx)(n.code,{children:"lm_prior_model (str | None)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.lm_prior_tau",children:(0,l.jsx)(n.code,{children:"lm_prior_tau (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.loss_scale",children:(0,l.jsx)(n.code,{children:"loss_scale (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.max_grad_norm",children:(0,l.jsx)(n.code,{children:"max_grad_norm (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.normalization",children:(0,l.jsx)(n.code,{children:"normalization (Literal['sents', 'tokens'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.num_workers",children:(0,l.jsx)(n.code,{children:"num_workers (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.param_init",children:(0,l.jsx)(n.code,{children:"param_init (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.param_init_method",children:(0,l.jsx)(n.code,{children:"param_init_method (Literal['xavier_uniform', 'uniform', 'normal'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.pre_word_vecs_dec",children:(0,l.jsx)(n.code,{children:"pre_word_vecs_dec (str | None)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.pre_word_vecs_enc",children:(0,l.jsx)(n.code,{children:"pre_word_vecs_enc (str | None)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.prefetch_factor",children:(0,l.jsx)(n.code,{children:"prefetch_factor (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.save_checkpoint_steps",children:(0,l.jsx)(n.code,{children:"save_checkpoint_steps (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.save_format",children:(0,l.jsx)(n.code,{children:"save_format (Literal['pytorch', 'safetensors'])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.score_threshold",children:(0,l.jsx)(n.code,{children:"score_threshold (float)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.single_pass",children:(0,l.jsx)(n.code,{children:"single_pass (bool)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.train_from",children:(0,l.jsx)(n.code,{children:"train_from (str | None)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.train_steps",children:(0,l.jsx)(n.code,{children:"train_steps (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.truncated_decoder",children:(0,l.jsx)(n.code,{children:"truncated_decoder (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.update_vocab",children:(0,l.jsx)(n.code,{children:"update_vocab (bool)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.use_ckpting",children:(0,l.jsx)(n.code,{children:"use_ckpting (List[str])"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.valid_batch_size",children:(0,l.jsx)(n.code,{children:"valid_batch_size (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.valid_steps",children:(0,l.jsx)(n.code,{children:"valid_steps (int)"})})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.zero_out_prompt_loss",children:(0,l.jsx)(n.code,{children:"zero_out_prompt_loss (bool)"})})}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validators:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"_validate_running_config"})," \xbb ",(0,l.jsx)(n.code,{children:"all fields"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.checkpointing_layers",children:(0,l.jsx)(n.code,{children:"checkpointing_layers"})})," \xbb ",(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.use_ckpting",children:(0,l.jsx)(n.code,{children:"use_ckpting"})})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-accum_count--listint--1",children:[(0,l.jsx)(n.em,{children:"field"})," accum_count ",(0,l.jsx)(n.em,{children:": List[int]"})," ",(0,l.jsx)(n.em,{children:"= [1]"})]}),"\n",(0,l.jsx)(n.p,{children:"Accumulate gradient this many times. Approximately equivalent to updating batch_size * accum_count batches at once. Recommended for transformer."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-accum_steps--listint--0",children:[(0,l.jsx)(n.em,{children:"field"})," accum_steps ",(0,l.jsx)(n.em,{children:": List[int]"})," ",(0,l.jsx)(n.em,{children:"= [0]"})]}),"\n",(0,l.jsx)(n.p,{children:"Steps at which accum_count values change."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-apex_opt_level--literal-o0-o1-o2-o3--",children:[(0,l.jsx)(n.em,{children:"field"})," apex_opt_level ",(0,l.jsx)(n.em,{children:": Literal['', 'O0', 'O1', 'O2', 'O3']"})," ",(0,l.jsx)(n.em,{children:"= ''"})]}),"\n",(0,l.jsxs)(n.p,{children:["For FP16 training, the opt_level to use. See ",(0,l.jsx)(n.a,{href:"https://nvidia.github.io/apex/amp.html#opt-levels",children:"https://nvidia.github.io/apex/amp.html#opt-levels"}),"."]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-attention_dropout--listfloat--01",children:[(0,l.jsx)(n.em,{children:"field"})," attention_dropout ",(0,l.jsx)(n.em,{children:": List[float]"})," ",(0,l.jsx)(n.em,{children:"= [0.1]"})]}),"\n",(0,l.jsx)(n.p,{children:"Attention dropout probability."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-average_decay--float--00",children:[(0,l.jsx)(n.em,{children:"field"})," average_decay ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.0"})]}),"\n",(0,l.jsxs)(n.p,{children:["Exponential moving average decay (",(0,l.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Moving_average",children:"https://en.wikipedia.org/wiki/Moving_average"}),"). Set to other than 0 (e.g. 1e-4) to activate. Similar to Marian NMT implementation (",(0,l.jsx)(n.a,{href:"http://www.aclweb.org/anthology/P18-4020",children:"http://www.aclweb.org/anthology/P18-4020"}),")."]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-average_every--int--1",children:[(0,l.jsx)(n.em,{children:"field"})," average_every ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 1"})]}),"\n",(0,l.jsx)(n.p,{children:"Step for moving average. Default is every update if average_decay is set."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-batch_size--int--64",children:[(0,l.jsx)(n.em,{children:"field"})," batch_size ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 64"})]}),"\n",(0,l.jsx)(n.p,{children:"Maximum batch size for training."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-batch_size_multiple--int--1",children:[(0,l.jsx)(n.em,{children:"field"})," batch_size_multiple ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 1"})]}),"\n",(0,l.jsx)(n.p,{children:"Batch size multiple for token batches."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-batch_type--literalsents-tokens--sents",children:[(0,l.jsx)(n.em,{children:"field"})," batch_type ",(0,l.jsx)(n.em,{children:": Literal['sents', 'tokens']"})," ",(0,l.jsx)(n.em,{children:"= 'sents'"})]}),"\n",(0,l.jsx)(n.p,{children:"Batch grouping for batch_size."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-bucket_size--int--262144",children:[(0,l.jsx)(n.em,{children:"field"})," bucket_size ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 262144"})]}),"\n",(0,l.jsx)(n.p,{children:"A bucket is a buffer of bucket_size examples to pick from the various corpora. The dynamic iterator batches batch_size items from the bucket and shuffle them."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-bucket_size_increment--int--0",children:[(0,l.jsx)(n.em,{children:"field"})," bucket_size_increment ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 0"})]}),"\n",(0,l.jsx)(n.p,{children:"Bucket size incremented with this amount of examples at each new bucket (up to bucket_size)."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-bucket_size_init--int---1",children:[(0,l.jsx)(n.em,{children:"field"})," bucket_size_init ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= -1"})]}),"\n",(0,l.jsx)(n.p,{children:"Bucket size is initialized with this amount of examples (see bucket_size_increment)."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-data_type--str--none--text",children:[(0,l.jsx)(n.em,{children:"field"})," data_type ",(0,l.jsx)(n.em,{children:": str | None"})," ",(0,l.jsx)(n.em,{children:"= 'text'"})]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-dropout--listfloat--03",children:[(0,l.jsx)(n.em,{children:"field"})," dropout ",(0,l.jsx)(n.em,{children:": List[float]"})," ",(0,l.jsx)(n.em,{children:"= [0.3]"})]}),"\n",(0,l.jsx)(n.p,{children:"Dropout probability."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-dropout_steps--listint--0",children:[(0,l.jsx)(n.em,{children:"field"})," dropout_steps ",(0,l.jsx)(n.em,{children:": List[int]"})," ",(0,l.jsx)(n.em,{children:"= [0]"})]}),"\n",(0,l.jsx)(n.p,{children:"Steps at which dropout changes."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-dummy_load--bool--none--false",children:[(0,l.jsx)(n.em,{children:"field"})," dummy_load ",(0,l.jsx)(n.em,{children:": bool | None"})," ",(0,l.jsx)(n.em,{children:"= False"})]}),"\n",(0,l.jsx)(n.p,{children:"Ignore some warnings if we are only loading the configuration prior to other operations, e.g. in train_from context."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-early_stopping--int--0",children:[(0,l.jsx)(n.em,{children:"field"})," early_stopping ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 0"})]}),"\n",(0,l.jsx)(n.p,{children:"Number of validation steps without improving that will trigger early stop of training."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-early_stopping_criteria--str--none--none",children:[(0,l.jsx)(n.em,{children:"field"})," early_stopping_criteria ",(0,l.jsx)(n.em,{children:": str | None"})," ",(0,l.jsx)(n.em,{children:"= None"})]}),"\n",(0,l.jsx)(n.p,{children:"Criteria to use for early stopping."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-estim_loss_lambda--listfloat--10",children:[(0,l.jsx)(n.em,{children:"field"})," estim_loss_lambda ",(0,l.jsx)(n.em,{children:": List[float]"})," ",(0,l.jsx)(n.em,{children:"= [1.0]"})]}),"\n",(0,l.jsx)(n.p,{children:"Weight applied to estimator loss"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-estim_loss_lambda_steps--listint--0",children:[(0,l.jsx)(n.em,{children:"field"})," estim_loss_lambda_steps ",(0,l.jsx)(n.em,{children:": List[int]"})," ",(0,l.jsx)(n.em,{children:"= [0]"})]}),"\n",(0,l.jsx)(n.p,{children:"Steps at which estimator loss lambda changes"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-freeze_decoder--bool--false",children:[(0,l.jsx)(n.em,{children:"field"})," freeze_decoder ",(0,l.jsx)(n.em,{children:": bool"})," ",(0,l.jsx)(n.em,{children:"= False"})]}),"\n",(0,l.jsx)(n.p,{children:"Freeze parameters in decoder."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-freeze_encoder--bool--false",children:[(0,l.jsx)(n.em,{children:"field"})," freeze_encoder ",(0,l.jsx)(n.em,{children:": bool"})," ",(0,l.jsx)(n.em,{children:"= False"})]}),"\n",(0,l.jsx)(n.p,{children:"Freeze parameters in encoder."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-keep_checkpoint--int---1",children:[(0,l.jsx)(n.em,{children:"field"})," keep_checkpoint ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= -1"})]}),"\n",(0,l.jsx)(n.p,{children:"Number of checkpoints to retain. (-1 retains all)"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-label_smoothing--float--00",children:[(0,l.jsx)(n.em,{children:"field"})," label_smoothing ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.0"})]}),"\n",(0,l.jsxs)(n.p,{children:["Label smoothing value epsilon. Probability of all non-true labels will be smoothed by epsilon/(vocab_size-1). Set to 0 to turn off label smoothing. (",(0,l.jsx)(n.a,{href:"https://arxiv.org/abs/1512.00567",children:"https://arxiv.org/abs/1512.00567"}),")"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-lm_prior_lambda--float--00",children:[(0,l.jsx)(n.em,{children:"field"})," lm_prior_lambda ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.0"})]}),"\n",(0,l.jsx)(n.p,{children:"LM Prior Lambda"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-lm_prior_model--str--none--none",children:[(0,l.jsx)(n.em,{children:"field"})," lm_prior_model ",(0,l.jsx)(n.em,{children:": str | None"})," ",(0,l.jsx)(n.em,{children:"= None"})]}),"\n",(0,l.jsx)(n.p,{children:"LM model to use to train the TM."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-lm_prior_tau--float--10",children:[(0,l.jsx)(n.em,{children:"field"})," lm_prior_tau ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 1.0"})]}),"\n",(0,l.jsx)(n.p,{children:"LM Prior Tau"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-loss_scale--float--00",children:[(0,l.jsx)(n.em,{children:"field"})," loss_scale ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.0"})]}),"\n",(0,l.jsx)(n.p,{children:"For FP16 training, the static loss scale to use. If not set, the loss scale is dynamically computed."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-max_grad_norm--float--5",children:[(0,l.jsx)(n.em,{children:"field"})," max_grad_norm ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 5"})]}),"\n",(0,l.jsx)(n.p,{children:"If the norm of the gradient vector exceeds this value, renormalize it to have the norm equal to max_grad_norm."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-normalization--literalsents-tokens--sents",children:[(0,l.jsx)(n.em,{children:"field"})," normalization ",(0,l.jsx)(n.em,{children:": Literal['sents', 'tokens']"})," ",(0,l.jsx)(n.em,{children:"= 'sents'"})]}),"\n",(0,l.jsx)(n.p,{children:"Normalization method of the gradient."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-num_workers--int--2",children:[(0,l.jsx)(n.em,{children:"field"})," num_workers ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 2"})]}),"\n",(0,l.jsx)(n.p,{children:"Number of workers for pytorch.DataLoader objects."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-param_init--float--01",children:[(0,l.jsx)(n.em,{children:"field"})," param_init ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.1"})]}),"\n",(0,l.jsx)(n.p,{children:"Support value for uniform distribution parameters initialization. Set to 0 not to use initialization."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-param_init_method--literalxavier_uniform-uniform-normal--uniform",children:[(0,l.jsx)(n.em,{children:"field"})," param_init_method ",(0,l.jsx)(n.em,{children:": Literal['xavier_uniform', 'uniform', 'normal']"})," ",(0,l.jsx)(n.em,{children:"= 'uniform'"})]}),"\n",(0,l.jsx)(n.p,{children:"Parameter initialization method."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-pre_word_vecs_dec--str--none--none",children:[(0,l.jsx)(n.em,{children:"field"})," pre_word_vecs_dec ",(0,l.jsx)(n.em,{children:": str | None"})," ",(0,l.jsx)(n.em,{children:"= None"})]}),"\n",(0,l.jsx)(n.p,{children:"If a valid path is specified, will load pretrained word embeddings on the decoder side."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-pre_word_vecs_enc--str--none--none",children:[(0,l.jsx)(n.em,{children:"field"})," pre_word_vecs_enc ",(0,l.jsx)(n.em,{children:": str | None"})," ",(0,l.jsx)(n.em,{children:"= None"})]}),"\n",(0,l.jsx)(n.p,{children:"If a valid path is specified, will load pretrained word embeddings on the encoder side."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-prefetch_factor--int--200",children:[(0,l.jsx)(n.em,{children:"field"})," prefetch_factor ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 200"})]}),"\n",(0,l.jsx)(n.p,{children:"Number of mini-batches loaded in advance to avoid the GPU waiting during processing of next bucket."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-save_checkpoint_steps--int--5000",children:[(0,l.jsx)(n.em,{children:"field"})," save_checkpoint_steps ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 5000"})]}),"\n",(0,l.jsx)(n.p,{children:"Frequency of checkpoint saving (in steps)."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-save_format--literalpytorch-safetensors--pytorch",children:[(0,l.jsx)(n.em,{children:"field"})," save_format ",(0,l.jsx)(n.em,{children:": Literal['pytorch', 'safetensors']"})," ",(0,l.jsx)(n.em,{children:"= 'pytorch'"})]}),"\n",(0,l.jsx)(n.p,{children:"Format to save the model weights."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-score_threshold--float--068",children:[(0,l.jsx)(n.em,{children:"field"})," score_threshold ",(0,l.jsx)(n.em,{children:": float"})," ",(0,l.jsx)(n.em,{children:"= 0.68"})]}),"\n",(0,l.jsx)(n.p,{children:"Threshold to filterout data"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-single_pass--bool--false",children:[(0,l.jsx)(n.em,{children:"field"})," single_pass ",(0,l.jsx)(n.em,{children:": bool"})," ",(0,l.jsx)(n.em,{children:"= False"})]}),"\n",(0,l.jsx)(n.p,{children:"Make a single pass over the training dataset."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-train_from--str--none--none",children:[(0,l.jsx)(n.em,{children:"field"})," train_from ",(0,l.jsx)(n.em,{children:": str | None"})," ",(0,l.jsx)(n.em,{children:"= None"})]}),"\n",(0,l.jsx)(n.p,{children:"Pretrained model/checkpoint weights to continue training from."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-train_steps--int--100000",children:[(0,l.jsx)(n.em,{children:"field"})," train_steps ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 100000"})]}),"\n",(0,l.jsx)(n.p,{children:"Number of training steps."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-truncated_decoder--int--0",children:[(0,l.jsx)(n.em,{children:"field"})," truncated_decoder ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 0"})]}),"\n",(0,l.jsx)(n.p,{children:"Truncated bptt."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-update_vocab--bool--false",children:[(0,l.jsx)(n.em,{children:"field"})," update_vocab ",(0,l.jsx)(n.em,{children:": bool"})," ",(0,l.jsx)(n.em,{children:"= False"})]}),"\n",(0,l.jsx)(n.p,{children:"Update source and target existing vocabularies."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-use_ckpting--liststr--",children:[(0,l.jsx)(n.em,{children:"field"})," use_ckpting ",(0,l.jsx)(n.em,{children:": List[str]"})," ",(0,l.jsx)(n.em,{children:"= []"})]}),"\n",(0,l.jsx)(n.p,{children:"Use gradient checkpointing for those modules."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.checkpointing_layers",children:(0,l.jsx)(n.code,{children:"checkpointing_layers"})})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-valid_batch_size--int--32",children:[(0,l.jsx)(n.em,{children:"field"})," valid_batch_size ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 32"})]}),"\n",(0,l.jsx)(n.p,{children:"Maximum batch size for validation."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-valid_steps--int--10000",children:[(0,l.jsx)(n.em,{children:"field"})," valid_steps ",(0,l.jsx)(n.em,{children:": int"})," ",(0,l.jsx)(n.em,{children:"= 10000"})]}),"\n",(0,l.jsx)(n.p,{children:"Frequency of validation, in steps."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"field-zero_out_prompt_loss--bool--false",children:[(0,l.jsx)(n.em,{children:"field"})," zero_out_prompt_loss ",(0,l.jsx)(n.em,{children:": bool"})," ",(0,l.jsx)(n.em,{children:"= False"})]}),"\n",(0,l.jsx)(n.p,{children:"Set the prompt loss to zero. Mostly for LLM finetuning. Will be enabled only if the insert_mask_before_placeholder transform is applied."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Validated by:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"_validate_running_config"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.h4,{id:"validator-checkpointing_layers----use_ckptingsource",children:[(0,l.jsx)(n.em,{children:"validator"})," checkpointing_layers  ",(0,l.jsx)(n.em,{children:"\xbb"}),"  ",(0,l.jsx)(n.a,{href:"#eole.config.training.TrainingConfig.use_ckpting",children:(0,l.jsx)(n.em,{children:"use_ckpting"})}),(0,l.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/config/training.py#L307-L313",children:"[source]"})]}),"\n",(0,l.jsxs)(n.h4,{id:"get_model_pathsource",children:["get_model_path()",(0,l.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/config/training.py#L315-L320",children:"[source]"})]}),"\n",(0,l.jsxs)(n.h4,{id:"property-storage_dtype--dtypesource",children:[(0,l.jsx)(n.em,{children:"property"})," storage_dtype ",(0,l.jsx)(n.em,{children:": dtype"}),(0,l.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/config/training.py#L282-L305",children:"[source]"})]}),"\n",(0,l.jsx)(n.p,{children:"Deduce which dtype to use for main model parameters.\nE.g. with mixed precision a copy is kept in float32."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>d});var l=i(6540);const t={},r=l.createContext(t);function s(e){const n=l.useContext(r);return l.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),l.createElement(r.Provider,{value:n},e.children)}}}]);