## Whisper inference config for LibriSpeech evaluation
## Used by eval_librispeech.py â€” model_path, src, output, gpu_ranks
## are overridden via CLI args.

data_type: audio
beam_size: 5
max_length: 448
batch_type: sents
batch_size: 1
gpu_ranks: [0]