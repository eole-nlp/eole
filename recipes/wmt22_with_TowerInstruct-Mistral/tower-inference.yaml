# Model info
model_path: ["${EOLE_MODEL_DIR}/TowerInstruct-Mistral-7b-v0.2"]

# Inference
seed: 42
max_length: 512
batch_type: tokens
batch_size: 8192
world_size: 1
gpu_ranks: [0]
#parallel_mode: "tensor_parallel"
#quant_layers: ['gate_up_proj', 'down_proj', 'up_proj', 'linear_values', 'linear_query', 'linear_keys', 'final_linear']
#quant_type: "bnb_NF4"
compute_dtype: fp16
top_k: 0
top_p: 0.0
#temperature: 0.9
beam_size: 1
n_best: 1
report_time: true
src: None

